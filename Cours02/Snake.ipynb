{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7c69e8-636f-4f86-85bc-c6dcab729625",
   "metadata": {},
   "source": [
    "# TP - Environnement Snake\n",
    "\n",
    "Les entrainements d'agents de ce notebook peuvent être gourmands en puissance de calcul. Si votre machine est trop lente, basculez sur Colab.\n",
    "\n",
    "Pour commencer, quelques cellules utilitaires pour une meilleure expérience *noteboook* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fde99a9-cb96-4992-b214-ec89943ec4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uniquement utilse sous Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    !rm -rf ESGI-M2-IABD/\n",
    "    !git clone https://github.com/pcouy/ESGI-M2-IABD\n",
    "    !pip install --upgrade pip\n",
    "    !pip install ESGI-M2-IABD/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e351462b-c7a1-4bb7-bfc0-1ffc0411cc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea, div.output_scroll { max-height: 70vh; height:70vh; resize: vertical;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modification de la taille des sorties scrollables\n",
    "# Rend également les sorties scrollables redimensionnables\n",
    "from IPython.display import HTML, Image, display\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea, div.output_scroll { max-height: 70vh; height:70vh; resize: vertical;}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d610588-98aa-4a70-8adc-fcf4de46c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions utilitaires pour afficher interactivement les vidéos des épisodes de test\n",
    "# ATTENTION : Le slider de view_videos ne fonctionne que s'il n'y a pas d'exécution déjà en cours !\n",
    "import os, io, glob, base64, threading\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import HTML, Image, display, Video\n",
    "\n",
    "def load_and_display(path):\n",
    "    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        raise NameError(\"Cannot access: {}\".format(path))\n",
    "\n",
    "    video = io.open(path, \"r+b\").read()\n",
    "    encoded = base64.b64encode(video)\n",
    "\n",
    "    display(HTML(\n",
    "        data=\"\"\"\n",
    "        <video alt=\"test\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
    "        </video>\n",
    "        \"\"\".format(encoded.decode(\"ascii\"))\n",
    "    ))\n",
    "\n",
    "def show_last_video(agent_save_dir):\n",
    "    dirname = os.path.join(agent_save_dir, \"videos\")\n",
    "    files = sorted([f for f in os.listdir(dirname)])\n",
    "    file = files[-1]\n",
    "    path = os.path.join(dirname, file, \"rl-video-episode-0.mp4\")\n",
    "    load_and_display(path)\n",
    "\n",
    "def view_videos(agent):\n",
    "    dirname = os.path.join(agent.save_dir, \"videos\")\n",
    "    files = sorted([f for f in os.listdir(dirname)])\n",
    "    print(files)\n",
    "    N = len(files)\n",
    "    def d(file: str) -> None:\n",
    "        path = os.path.join(dirname, file, \"rl-video-episode-0.mp4\")\n",
    "        load_and_display(path)\n",
    "    interact(d, file=widgets.SelectionSlider(options=files, value=files[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80816525-7076-44a1-a99f-a7dd99db8dd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Agent tabulaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc5609-688d-43be-9b6b-e81ef6e9df72",
   "metadata": {},
   "source": [
    "La cellule ci-dessous donne un exemple d'entraînement d'agent tabulaire sur le jeu Snake. Lancez la cellule, et constatez l'apprentissage de l'agent avec les données de sorties (dossier `results`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b499accb-8cac-4fe3-9436-de91ddd44eb4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import code_tp as TP\n",
    "from code_tp import agents, value_functions, policies\n",
    "from code_tp import wrappers\n",
    "import gym\n",
    "    \n",
    "env = agents.snake.make_tabular_snake_env(4,5)\n",
    "env = wrappers.utils.BoredomWrapper(env)\n",
    "a=TP.create_agent_from_env(env,\n",
    "agent_class=agents.base.QLearningAgent,\n",
    "value_class=value_functions.tabular.TabularQValue,\n",
    "policy_class=policies.greedy.EGreedyPolicy,\n",
    "agent_args={\n",
    "    'gamma':0.99\n",
    "},\n",
    "value_args={\n",
    "    'lr':0.5, 'lr_decay':5e-7, 'lr_min':0.1,\n",
    "    'default_value': 0\n",
    "},\n",
    "policy_args={\n",
    "    'greedy_policy_class': policies.greedy.GreedyQPolicy,\n",
    "    'epsilon': 1, 'epsilon_decay': 2e-4, 'epsilon_min': 0.05,\n",
    "    'epsilon_test':0\n",
    "})\n",
    "a.train(2000, 200, test_callbacks=[show_last_video])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df20e08-fcfb-44a2-88de-61f34d5f5bdd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.plot_stats(save_dir=None)\n",
    "view_videos(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be60336-5a94-4780-8636-2be7e8d8f33e",
   "metadata": {},
   "source": [
    "Consultez la [documentation du TP](https://pcouy.github.io/ESGI-M2-IABD/index.html), et particulièrement la [documentation et le code de `agents.snake`](https://pcouy.github.io/ESGI-M2-IABD/code_tp/agents/snake.html) ainsi que [la classe `TabularObservation`](https://pcouy.github.io/ESGI-M2-IABD/code_tp/wrappers/utils.html#TabularObservation).\n",
    "\n",
    ">Les trois classes concernées héritent toutes de la classe `gym.core.ObservationWrapper`. Trouvez le code de cette classe sur [le dépôt Github d'OpenAI Gym](https://github.com/openai/gym/). À quoi sert cette classe ?\n",
    ">\n",
    ">Pourquoi utiliser les classes `TabularObservation` et celles contenues dans `agent.snake` ? Que se serait-il passé si on avait appliqué l'algorithme de *Q-learning* tabulaire naïvement (*ie* sans utiliser ces *wrappers*) ?\n",
    ">\n",
    ">Testez l'agent tabulaire pour différentes valeurs des paramètres de `agents.snake.make_tabular_snake_env`.\n",
    ">\n",
    ">Que se passe-t-il lorsque la taille de la grille augmente ? Que se passe-t-il si le nombre de niveaux de discrétisation est trop élevé ? trop faible ?\n",
    ">\n",
    ">Quelle influence a le paramètre `default_value` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecc2550-36f6-46b4-9bcd-ec6322db2b39",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "571038bf-fc34-4772-af5c-4b555339c1f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Approximation linéaire de la fonction de valeur\n",
    "\n",
    ">Consultez les documentations de `agents.snake.make_feature_snake_env` et `value_functions.linear` pour entrainer un agent utilisant une fonction de valeur approximée linéairement.\n",
    ">\n",
    ">Un taux d'apprentissage de 0.5 est-t-il toujours adapté ?\n",
    ">\n",
    ">Commentez les différences d'apprentissage avec l'agent linéaire (vitesse d'apprentissage, qualité de la stratégie, conséquences des changements de taille de grille)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc076720-e659-430b-9406-72a9e4fba8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciez les classes nécessaires et lancez l'entrainement ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6ae0d-bb95-477d-8abf-67ac638c1551",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "696a4990-a454-4c1f-8e7c-84c4f1e36176",
   "metadata": {},
   "source": [
    "> Étudiez soigneusement [le code de la fonction de valeur linéaire](https://pcouy.github.io/ESGI-M2-IABD/code_tp/value_functions/linear.html). En quoi cette fonction de valeur s'apparente-t-elle déjà à un \"réseau\" de neurones contenant un unique neurone ?\n",
    "> \n",
    "> Pouvez vous reconnaitre la ligne de code implémentant la descente de gradient dans la classe `LinearQValue` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd68c1e6-112a-4cd4-9058-6f4603227253",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23f95434-7d42-4e59-9c73-80fddccdc483",
   "metadata": {},
   "source": [
    "## Initiation à PyTorch\n",
    "\n",
    "Pour toutes les implémentations d'apprentissage **profond** (*ie* basées sur des réseaux de neurones) par renforcement de la suite du cours, nous utiliserons le [*framework* **PyTorch**](https://pytorch.org/). \n",
    "\n",
    "Commencez par installer la librairie :\n",
    "\n",
    "```\n",
    "pip install torch torchvision\n",
    "```\n",
    "\n",
    "Vous allez dans un premier temps suivre le [tutoriel d'initiation à PyTorch](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html). Il est vivement conseillé de sauvegarder les notebooks utilisés pour suivre le tutoriel (chaque chapitre du tutoriel est un notebook), afin de conserver une trace qui vous servira de référence pour la suite du cours.\n",
    "\n",
    "Voici quelques conseils pour tirer profit du tutoriel au maximum :\n",
    "\n",
    "* Utilisez les cellules *markdown* pour produire des documents qui se suffisent à eux-même. Utilisez les différents niveaux de titres pour vous retrouver facilement dans votre document à l'avenir.\n",
    "* À toutes les étapes du tutoriel, n'hésitez pas à sortir du chemin tracé et à expérimenter vous même (sur les manipulations de tenseurs, sur le valeurs des hyperparamètres, différentes architectures de réseaux de neurones, etc) sur tout ce qui éveille votre curiosité. Conservez le code de ces expériences dans des cellules de vos *notebooks* et gardez une trace de ce que vous avez découvert (bonnes valeurs des hyperparamètres, piège à éviter sur certaines manipulations de tenseurs, etc)\n",
    "* Appliquez vous à suivre toutes les étapes du tutoriel, même celles qui vous semblent triviales, et intégrez les dans votre *notebook* à la manière d'une \"fiche de révision\".\n",
    "* Usez et abusez de [la documentation](https://pytorch.org/docs/stable/index.html).\n",
    "* Le code de la dernière partie du tutoriel (\"Training a Classifier\") peut être lent à exécuter sur certaines machines. Ne pas hésiter à basculer sur [Google Colab](https://colab.research.google.com/) pour cette partie.\n",
    "* Sollicitez moi autant que nécessaire, à l'oral pendant les séances, ou sur l'espace \"Discussions\" du *Github*, dès qu'un point vous semble obscure ou vous bloque.\n",
    "\n",
    "Tous ces conseils, bien que chronophages, vous permettront de dompter au plus vite cet outil complexe. La documentation officielle est un outil précieux, mais votre familiarité avec vos propres notes vous feront gagner beaucoup de temps pour la suite.\n",
    "\n",
    "Une bonne maitrise de *PyTorch* sera nécessaire pour suivre correctement les exercices pratiques de la suite du cours.\n",
    "\n",
    "> Après avoir terminé le tutoriel, réimplémentez l'approximation linéaire de la fonction de valeur, en utilisant les outils de PyTorch : \n",
    ">\n",
    "> * Vous remplacerez le tableau *Numpy* `self.weights` dans la classe `LinearQValue` par un module *PyTorch* (classe `Net` ci-dessous), *ie* un réseau de neurones. Ce réseau sera équivalent au réseau implémenté par l'approximation linéaire fournie (classe `LinearQValue`). ([Indice](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html))\n",
    "> * Au lieu de faire \"manuellement\" la mise à jour des poids, vous utiliserez un [optimiseur SGD (pour Stochastic Gradient Descent)](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD). Vous conserverez tous les paramètres par défaut, à l'exception du taux d'apprentissage que vous ajusterez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf946d-93b0-4995-9112-e85eff689549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from value_functions.base import DiscreteQFunction\n",
    "\n",
    "class Net(nn.Module):\n",
    "    pass # REMPLIR ICI\n",
    "\n",
    "class TorchLinearQValue(DiscreteQFunction):\n",
    "     def __init__(self, env, default_value=0, *args, **kwargs):\n",
    "        super().__init__(env, *args, **kwargs) # A CONSERVER\n",
    "        # REMPLIR ICI\n",
    "\n",
    "    def add_bias(self, state):\n",
    "        pass # REMPLIR ICI\n",
    "\n",
    "    def __call__(self, state, action):\n",
    "        pass # REMPLIR ICI\n",
    "\n",
    "    def from_state(self, state):\n",
    "        pass # REMPLIR ICI\n",
    "    \n",
    "    def update(self, state, action, target_value):\n",
    "        # REMPLIR ICI\n",
    "        super().update(state, action, target_value) # A CONSERVER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a6c06-6912-4a0f-9d96-27db484f373d",
   "metadata": {},
   "source": [
    "Votre nouvelle fonction de valeur doit pouvoir remplacer \"telle quelle\" l'approximation linéaire en *Numpy* fournie (dans l'entrainement de l'agent ci-dessus, vous devez pouvoir remplacer `value_functions.linear.LinearQValue` par `TorchLinearQValue`).\n",
    "\n",
    "> Instanciez et entrainez un agent utilisant la fonction de valeur que vous venez de définir, et confirmez son bon fonctionnement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0b2bb-b764-474d-bf67-2ae28a77daab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16e9724d-165b-410c-b1cd-e1a3c9f959dd",
   "metadata": {},
   "source": [
    "La fonction de valeur que vous venez d'implémenter (classe `TorchLinearQValue`) peut désormais vous servir de base pour créer des fonctions de valeur *neurales* arbitrairement complexes (attention cependant à la dimension des observations qui doit être égale à la dimension des *inputs* du réseau de neurone).\n",
    "\n",
    "> Reprenez votre classe `Net` + le code d'instanciation et d'endtrainement ci-dessus. Copiez-collez les ci-dessous. Modifiez la classe Net pour expérimenter avec l'architecture du réseau de neurones. Avant de tester chaque modification, essayez de prédire ses conséquences sur l'apprentissage de l'agent.\n",
    ">\n",
    "> * Ajoutez une couche au réseau de neurones. Faites varier la taille de cette couche.\n",
    "> * Si vous trouvez une bonne valeur pour la taille de cette nouvelle couche, essayez d'ajouter plus de couches de la même taille.\n",
    ">\n",
    "> Quelle sont les conséquences de ces modifications sur l'apprentissage de l'agent ? Attendiez-vous ce résultat ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
