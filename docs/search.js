window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = {"version": "0.9.5", "fields": ["qualname", "fullname", "doc"], "ref": "fullname", "documentStore": {"docs": {"code_tp": {"fullname": "code_tp", "modulename": "code_tp", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.dict_to_dirname": {"fullname": "code_tp.dict_to_dirname", "modulename": "code_tp", "qualname": "dict_to_dirname", "type": "function", "doc": "<p></p>\n", "parameters": ["x"], "funcdef": "def"}, "code_tp.class_and_args_to_dirname": {"fullname": "code_tp.class_and_args_to_dirname", "modulename": "code_tp", "qualname": "class_and_args_to_dirname", "type": "function", "doc": "<p></p>\n", "parameters": ["class_", "args_"], "funcdef": "def"}, "code_tp.date_dirname": {"fullname": "code_tp.date_dirname", "modulename": "code_tp", "qualname": "date_dirname", "type": "function", "doc": "<p></p>\n", "parameters": [], "funcdef": "def"}, "code_tp.create_agent_and_env": {"fullname": "code_tp.create_agent_and_env", "modulename": "code_tp", "qualname": "create_agent_and_env", "type": "function", "doc": "<p>A priori non utilis\u00e9e</p>\n", "parameters": ["agent_class", "agent_args", "env_name", "env_wrappers"], "funcdef": "def"}, "code_tp.create_agent_from_env": {"fullname": "code_tp.create_agent_from_env", "modulename": "code_tp", "qualname": "create_agent_from_env", "type": "function", "doc": "<p>Fonction utilitaire permettant de lancer une exp\u00e9rience en instanciant l'agent,\nla fonction de valeur et la politique correctement, tout en enregistrant les\nparam\u00e8tres dans le dossier de l'exp\u00e9rience.</p>\n", "parameters": ["env", "agent_class", "value_class", "policy_class", "agent_args", "value_args", "policy_args"], "funcdef": "def"}, "code_tp.agents": {"fullname": "code_tp.agents", "modulename": "code_tp.agents", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.agents.base": {"fullname": "code_tp.agents.base", "modulename": "code_tp.agents.base", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.agents.base.Agent": {"fullname": "code_tp.agents.base.Agent", "modulename": "code_tp.agents.base", "qualname": "Agent", "type": "class", "doc": "<p>Classe de base pour tous les agents.</p>\n"}, "code_tp.agents.base.Agent.__init__": {"fullname": "code_tp.agents.base.Agent.__init__", "modulename": "code_tp.agents.base", "qualname": "Agent.__init__", "type": "function", "doc": "<ul>\n<li><code>env</code>: Environnement gym dans lequel l'agent va \u00e9voluer</li>\n<li><code>save_dir</code>: Dossier dans lequel les r\u00e9sultats de l'exp\u00e9rience seront sauvegard\u00e9s</li>\n<li><code>infos</code>: Dictionnaire qui sera sauvegard\u00e9 au format JSON dans le dossier de\n        l'exp\u00e9rience, utile pour y \u00e9crire les param\u00e8tres.</li>\n</ul>\n", "parameters": ["self", "env", "save_dir", "infos", "tensorboard_layout"], "funcdef": "def"}, "code_tp.agents.base.Agent.log_data": {"fullname": "code_tp.agents.base.Agent.log_data", "modulename": "code_tp.agents.base", "qualname": "Agent.log_data", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "key", "value"], "funcdef": "def"}, "code_tp.agents.base.Agent.select_action": {"fullname": "code_tp.agents.base.Agent.select_action", "modulename": "code_tp.agents.base", "qualname": "Agent.select_action", "type": "function", "doc": "<p>Prend un \u00e9tat en entr\u00e9e, renvoie une action</p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.agents.base.Agent.train_with_transition": {"fullname": "code_tp.agents.base.Agent.train_with_transition", "modulename": "code_tp.agents.base", "qualname": "Agent.train_with_transition", "type": "function", "doc": "<p>Met \u00e0 jour l'agent suite \u00e0 une transition. Les noms des param\u00e8tres sont explicites.\nLe param\u00e8tre <code>infos</code>, rarement utilis\u00e9, fait partie des r\u00e9ponses standardis\u00e9es des\nenvironnements gym, et est donc inclus</p>\n", "parameters": ["self", "state", "action", "next_state", "reward", "done", "infos"], "funcdef": "def"}, "code_tp.agents.base.Agent.step": {"fullname": "code_tp.agents.base.Agent.step", "modulename": "code_tp.agents.base", "qualname": "Agent.step", "type": "function", "doc": "<p>Effectue une action. Dans cette classe de base, est utilis\u00e9 uniquement pour appeler\nla m\u00e9thode <code>step</code> de l'environnement.</p>\n", "parameters": ["self", "action", "env"], "funcdef": "def"}, "code_tp.agents.base.Agent.run_episode": {"fullname": "code_tp.agents.base.Agent.run_episode", "modulename": "code_tp.agents.base", "qualname": "Agent.run_episode", "type": "function", "doc": "<p>Jouer un \u00e9pisode dans l'enfironnement. Le param\u00e8tre <code>test</code> d\u00e9termine si les transitions\nqui ont lieu durant l'\u00e9pisode doivent mettre \u00e0 jour l'agent.</p>\n", "parameters": ["self", "test"], "funcdef": "def"}, "code_tp.agents.base.Agent.run_n_episodes": {"fullname": "code_tp.agents.base.Agent.run_n_episodes", "modulename": "code_tp.agents.base", "qualname": "Agent.run_n_episodes", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "n", "test"], "funcdef": "def"}, "code_tp.agents.base.Agent.train": {"fullname": "code_tp.agents.base.Agent.train", "modulename": "code_tp.agents.base", "qualname": "Agent.train", "type": "function", "doc": "<p>Boucle d'entrainement.</p>\n\n<ul>\n<li><code>n_episodes</code>: nombre d'\u00e9pisodes durant lesquels entrainer l'agent</li>\n<li><code>test_interval</code>: lance un \u00e9pisode de test, et sauvegarde la vid\u00e9o, tous les <code>test_interval</code>\n                \u00e9pisodes</li>\n<li><code>train_callbacks</code>: Liste de fonctions \u00e0 appeler \u00e0 la fin de chaque \u00e9pisode d'entrainement</li>\n<li><code>test_callbacks</code>: Liste de fonctions \u00e0 appeler \u00e0 la fin de chaque \u00e9pisode de test</li>\n</ul>\n\n<p>Les callbacks prennent comme unique argument le dossier de sauvegarde</p>\n", "parameters": ["self", "n_episodes", "test_interval", "train_callbacks", "test_callbacks"], "funcdef": "def"}, "code_tp.agents.base.Agent.episode_end": {"fullname": "code_tp.agents.base.Agent.episode_end", "modulename": "code_tp.agents.base", "qualname": "Agent.episode_end", "type": "function", "doc": "<p>M\u00e9thode appel\u00e9e par <code>run_episode</code> \u00e0 la fin de chaque \u00e9pisode, re\u00e7oit le\nscore de l'\u00e9pisode achev\u00e9 comme argument.</p>\n", "parameters": ["self", "score"], "funcdef": "def"}, "code_tp.agents.base.Agent.plot_stats": {"fullname": "code_tp.agents.base.Agent.plot_stats", "modulename": "code_tp.agents.base", "qualname": "Agent.plot_stats", "type": "function", "doc": "<p>Trace les courbes des tableaux contenus dans <code>self.stats</code>. Si <code>save_dir</code> vaut <code>None</code>,\naffiche directement les courbes, sinon les sauvegarde.</p>\n", "parameters": ["self", "save_dir"], "funcdef": "def"}, "code_tp.agents.base.RandomAgent": {"fullname": "code_tp.agents.base.RandomAgent", "modulename": "code_tp.agents.base", "qualname": "RandomAgent", "type": "class", "doc": "<p>Agent effectuant une action al\u00e9atoire \u00e0 tous les pas de temps</p>\n"}, "code_tp.agents.base.RandomAgent.select_action": {"fullname": "code_tp.agents.base.RandomAgent.select_action", "modulename": "code_tp.agents.base", "qualname": "RandomAgent.select_action", "type": "function", "doc": "<p>Prend un \u00e9tat en entr\u00e9e, renvoie une action</p>\n", "parameters": ["self", "args", "kwargs"], "funcdef": "def"}, "code_tp.agents.base.RandomAgent.train_with_transition": {"fullname": "code_tp.agents.base.RandomAgent.train_with_transition", "modulename": "code_tp.agents.base", "qualname": "RandomAgent.train_with_transition", "type": "function", "doc": "<p>Met \u00e0 jour l'agent suite \u00e0 une transition. Les noms des param\u00e8tres sont explicites.\nLe param\u00e8tre <code>infos</code>, rarement utilis\u00e9, fait partie des r\u00e9ponses standardis\u00e9es des\nenvironnements gym, et est donc inclus</p>\n", "parameters": ["self", "args", "kwargs"], "funcdef": "def"}, "code_tp.agents.base.QLearningAgent": {"fullname": "code_tp.agents.base.QLearningAgent", "modulename": "code_tp.agents.base", "qualname": "QLearningAgent", "type": "class", "doc": "<p>Impl\u00e9mente l'algorithme du <em>Q-Learning</em></p>\n"}, "code_tp.agents.base.QLearningAgent.__init__": {"fullname": "code_tp.agents.base.QLearningAgent.__init__", "modulename": "code_tp.agents.base", "qualname": "QLearningAgent.__init__", "type": "function", "doc": "<ul>\n<li><code>env</code>: Environnement gym dans lequel l'agent \u00e9volue</li>\n<li><code>value_function</code>: Instance d'une fonction de valeur (voir <code>code_tp/value_functions</code>)</li>\n<li><code>policy</code>: Instance d'une politique (voir <code>code_tp/policies</code>)</li>\n<li><code>gamma</code>: Taux de discount de l'agent. Doit \u00eatre compris entre 0 et 1</li>\n</ul>\n", "parameters": ["self", "env", "value_function", "policy", "gamma", "kwargs"], "funcdef": "def"}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"fullname": "code_tp.agents.base.QLearningAgent.train_with_transition", "modulename": "code_tp.agents.base", "qualname": "QLearningAgent.train_with_transition", "type": "function", "doc": "<p>Met \u00e0 jour l'agent suite \u00e0 une transition. Les noms des param\u00e8tres sont explicites.\nLe param\u00e8tre <code>infos</code>, rarement utilis\u00e9, fait partie des r\u00e9ponses standardis\u00e9es des\nenvironnements gym, et est donc inclus</p>\n", "parameters": ["self", "state", "action", "next_state", "reward", "done", "infos"], "funcdef": "def"}, "code_tp.agents.base.QLearningAgent.eval_state": {"fullname": "code_tp.agents.base.QLearningAgent.eval_state", "modulename": "code_tp.agents.base", "qualname": "QLearningAgent.eval_state", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.agents.base.QLearningAgent.eval_state_batch": {"fullname": "code_tp.agents.base.QLearningAgent.eval_state_batch", "modulename": "code_tp.agents.base", "qualname": "QLearningAgent.eval_state_batch", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "states"], "funcdef": "def"}, "code_tp.agents.base.QLearningAgent.target_value_from_state": {"fullname": "code_tp.agents.base.QLearningAgent.target_value_from_state", "modulename": "code_tp.agents.base", "qualname": "QLearningAgent.target_value_from_state", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "next_state", "reward", "done"], "funcdef": "def"}, "code_tp.agents.base.QLearningAgent.target_value_from_state_batch": {"fullname": "code_tp.agents.base.QLearningAgent.target_value_from_state_batch", "modulename": "code_tp.agents.base", "qualname": "QLearningAgent.target_value_from_state_batch", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "next_states", "rewards", "dones"], "funcdef": "def"}, "code_tp.agents.base.QLearningAgent.select_action": {"fullname": "code_tp.agents.base.QLearningAgent.select_action", "modulename": "code_tp.agents.base", "qualname": "QLearningAgent.select_action", "type": "function", "doc": "<p>Prend un \u00e9tat en entr\u00e9e, renvoie une action</p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.agents.base.QLearningAgent.plot_stats": {"fullname": "code_tp.agents.base.QLearningAgent.plot_stats", "modulename": "code_tp.agents.base", "qualname": "QLearningAgent.plot_stats", "type": "function", "doc": "<p>Trace les courbes des tableaux contenus dans <code>self.stats</code>. Si <code>save_dir</code> vaut <code>None</code>,\naffiche directement les courbes, sinon les sauvegarde.</p>\n", "parameters": ["self", "save_dir"], "funcdef": "def"}, "code_tp.agents.base.SARSAAgent": {"fullname": "code_tp.agents.base.SARSAAgent", "modulename": "code_tp.agents.base", "qualname": "SARSAAgent", "type": "class", "doc": "<p>Impl\u00e9mente l'algorithme du <em>Q-Learning</em></p>\n"}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"fullname": "code_tp.agents.base.SARSAAgent.train_with_transition", "modulename": "code_tp.agents.base", "qualname": "SARSAAgent.train_with_transition", "type": "function", "doc": "<p>Met \u00e0 jour l'agent suite \u00e0 une transition. Les noms des param\u00e8tres sont explicites.\nLe param\u00e8tre <code>infos</code>, rarement utilis\u00e9, fait partie des r\u00e9ponses standardis\u00e9es des\nenvironnements gym, et est donc inclus</p>\n", "parameters": ["self", "state", "action", "next_state", "reward", "done", "infos"], "funcdef": "def"}, "code_tp.agents.gridworld": {"fullname": "code_tp.agents.gridworld", "modulename": "code_tp.agents.gridworld", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"fullname": "code_tp.agents.gridworld.GridworldTabularValueAgent", "modulename": "code_tp.agents.gridworld", "qualname": "GridworldTabularValueAgent", "type": "class", "doc": "<p>Ajoute un callback au <code>QLearningAgent</code> pour afficher la fonction de valeur superpos\u00e9e\n\u00e0 l'environnement. N'introduit aucune connaissance sp\u00e9cifique \u00e0 l'environnement dans\nle processus d'entrainement.</p>\n"}, "code_tp.agents.gridworld.GridworldTabularValueAgent.show_values": {"fullname": "code_tp.agents.gridworld.GridworldTabularValueAgent.show_values", "modulename": "code_tp.agents.gridworld", "qualname": "GridworldTabularValueAgent.show_values", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "save_dir"], "funcdef": "def"}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"fullname": "code_tp.agents.gridworld.GridworldTabularValueAgent.train", "modulename": "code_tp.agents.gridworld", "qualname": "GridworldTabularValueAgent.train", "type": "function", "doc": "<p>Boucle d'entrainement.</p>\n\n<ul>\n<li><code>n_episodes</code>: nombre d'\u00e9pisodes durant lesquels entrainer l'agent</li>\n<li><code>test_interval</code>: lance un \u00e9pisode de test, et sauvegarde la vid\u00e9o, tous les <code>test_interval</code>\n                \u00e9pisodes</li>\n<li><code>train_callbacks</code>: Liste de fonctions \u00e0 appeler \u00e0 la fin de chaque \u00e9pisode d'entrainement</li>\n<li><code>test_callbacks</code>: Liste de fonctions \u00e0 appeler \u00e0 la fin de chaque \u00e9pisode de test</li>\n</ul>\n\n<p>Les callbacks prennent comme unique argument le dossier de sauvegarde</p>\n", "parameters": ["self", "n_episodes", "test_interval", "train_callbacks", "test_callbacks"], "funcdef": "def"}, "code_tp.agents.replay_buffer": {"fullname": "code_tp.agents.replay_buffer", "modulename": "code_tp.agents.replay_buffer", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.agents.replay_buffer.ReplayBuffer": {"fullname": "code_tp.agents.replay_buffer.ReplayBuffer", "modulename": "code_tp.agents.replay_buffer", "qualname": "ReplayBuffer", "type": "class", "doc": "<p></p>\n"}, "code_tp.agents.replay_buffer.ReplayBuffer.__init__": {"fullname": "code_tp.agents.replay_buffer.ReplayBuffer.__init__", "modulename": "code_tp.agents.replay_buffer", "qualname": "ReplayBuffer.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "obs_shape", "max_size", "batch_size"], "funcdef": "def"}, "code_tp.agents.replay_buffer.ReplayBuffer.ready": {"fullname": "code_tp.agents.replay_buffer.ReplayBuffer.ready", "modulename": "code_tp.agents.replay_buffer", "qualname": "ReplayBuffer.ready", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.agents.replay_buffer.ReplayBuffer.store": {"fullname": "code_tp.agents.replay_buffer.ReplayBuffer.store", "modulename": "code_tp.agents.replay_buffer", "qualname": "ReplayBuffer.store", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "state", "action", "next_state", "reward", "done", "infos"], "funcdef": "def"}, "code_tp.agents.replay_buffer.ReplayBuffer.sample": {"fullname": "code_tp.agents.replay_buffer.ReplayBuffer.sample", "modulename": "code_tp.agents.replay_buffer", "qualname": "ReplayBuffer.sample", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"fullname": "code_tp.agents.replay_buffer.ReplayBufferAgent", "modulename": "code_tp.agents.replay_buffer", "qualname": "ReplayBufferAgent", "type": "class", "doc": "<p>Classe de base pour tous les agents.</p>\n"}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"fullname": "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__", "modulename": "code_tp.agents.replay_buffer", "qualname": "ReplayBufferAgent.__init__", "type": "function", "doc": "<ul>\n<li><code>env</code>: Environnement gym dans lequel l'agent va \u00e9voluer</li>\n<li><code>save_dir</code>: Dossier dans lequel les r\u00e9sultats de l'exp\u00e9rience seront sauvegard\u00e9s</li>\n<li><code>infos</code>: Dictionnaire qui sera sauvegard\u00e9 au format JSON dans le dossier de\n        l'exp\u00e9rience, utile pour y \u00e9crire les param\u00e8tres.</li>\n</ul>\n", "parameters": ["self", "env", "replay_buffer_class", "replay_buffer_args", "update_interval", "kwargs"], "funcdef": "def"}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"fullname": "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition", "modulename": "code_tp.agents.replay_buffer", "qualname": "ReplayBufferAgent.train_with_transition", "type": "function", "doc": "<p>Met \u00e0 jour l'agent suite \u00e0 une transition. Les noms des param\u00e8tres sont explicites.\nLe param\u00e8tre <code>infos</code>, rarement utilis\u00e9, fait partie des r\u00e9ponses standardis\u00e9es des\nenvironnements gym, et est donc inclus</p>\n", "parameters": ["self", "state", "action", "next_state", "reward", "done", "infos"], "funcdef": "def"}, "code_tp.agents.snake": {"fullname": "code_tp.agents.snake", "modulename": "code_tp.agents.snake", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.agents.snake.AddDirectionToSnakeState": {"fullname": "code_tp.agents.snake.AddDirectionToSnakeState", "modulename": "code_tp.agents.snake", "qualname": "AddDirectionToSnakeState", "type": "class", "doc": "<p>Wrapper gym qui ajoute \u00e0 l'observation du snake la direction de d\u00e9placement actuelle</p>\n"}, "code_tp.agents.snake.AddDirectionToSnakeState.__init__": {"fullname": "code_tp.agents.snake.AddDirectionToSnakeState.__init__", "modulename": "code_tp.agents.snake", "qualname": "AddDirectionToSnakeState.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "args", "kwargs"], "funcdef": "def"}, "code_tp.agents.snake.AddDirectionToSnakeState.observation": {"fullname": "code_tp.agents.snake.AddDirectionToSnakeState.observation", "modulename": "code_tp.agents.snake", "qualname": "AddDirectionToSnakeState.observation", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "observation"], "funcdef": "def"}, "code_tp.agents.snake.SnakeFeatureObservation": {"fullname": "code_tp.agents.snake.SnakeFeatureObservation", "modulename": "code_tp.agents.snake", "qualname": "SnakeFeatureObservation", "type": "class", "doc": "<p>Wrapper gym qui permet de transformer l'observation brute du snake en un \nensemble de <em>features expertes</em></p>\n"}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"fullname": "code_tp.agents.snake.SnakeFeatureObservation.__init__", "modulename": "code_tp.agents.snake", "qualname": "SnakeFeatureObservation.__init__", "type": "function", "doc": "<ul>\n<li><code>env</code>: Environnement \u00e0 envelopper</li>\n<li><code>grid_size</code>: Taille de la grille de l'environnement</li>\n<li><code>food_direction</code>: prend les valeurs <code>\"unit_vector\"</code> ou <code>\"angle\"</code>, d\u00e9termine si la direction\n        dans laquelle se trouve la nouriture doit \u00eatre indiqu\u00e9e par un vecteur unitaire\n        ou un angle</li>\n</ul>\n", "parameters": ["self", "env", "grid_size", "food_direction", "args", "kwargs"], "funcdef": "def"}, "code_tp.agents.snake.SnakeFeatureObservation.OC": {"fullname": "code_tp.agents.snake.SnakeFeatureObservation.OC", "modulename": "code_tp.agents.snake", "qualname": "SnakeFeatureObservation.OC", "type": "class", "doc": "<p>Object color used on observation encoding</p>\n"}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"fullname": "code_tp.agents.snake.SnakeFeatureObservation.observation", "modulename": "code_tp.agents.snake", "qualname": "SnakeFeatureObservation.observation", "type": "function", "doc": "<p>Prend en entr\u00e9e l'observation <code>s</code> et retourne l'observation dans le nouveau format</p>\n", "parameters": ["self", "s"], "funcdef": "def"}, "code_tp.agents.snake.make_feature_snake_env": {"fullname": "code_tp.agents.snake.make_feature_snake_env", "modulename": "code_tp.agents.snake", "qualname": "make_feature_snake_env", "type": "function", "doc": "<p>Fonction utilitaire retournant un environnement snake \u00e9quip\u00e9 du wrapper <code>SnakeFeatureObservation</code></p>\n\n<ul>\n<li><code>grid_size</code>: Taille de la grille (4 ; 8 ou 16)</li>\n<li><code>log_scale</code>: Si <code>True</code>, applique le wrapper <code>code_tp.wrappers.utils.LogScaleObs</code></li>\n<li><code>food_direction</code>: Voir <code>SnakeFeatureObservation</code></li>\n</ul>\n", "parameters": ["grid_size", "log_scale", "food_direction"], "funcdef": "def"}, "code_tp.agents.snake.make_tabular_snake_env": {"fullname": "code_tp.agents.snake.make_tabular_snake_env", "modulename": "code_tp.agents.snake", "qualname": "make_tabular_snake_env", "type": "function", "doc": "<p>Cr\u00e9\u00e9 un environnement snake aux \u00e9tats discrets (en discretisant les <em>features</em> de\n<code>SnakeFeatureObservation</code></p>\n\n<ul>\n<li><code>grid_size</code>: Taille de la grille (4 ; 8 ou 16)</li>\n<li><code>n_levels</code>: Tableau indiquant le nombre de valeurs possibles pour chaque <em>feature</em> discretis\u00e9e</li>\n<li><code>log_scale</code>: Appliquer le wrapper <code>LogScaleObs</code> avant de discr\u00e9tiser</li>\n</ul>\n", "parameters": ["grid_size", "n_levels", "log_scale"], "funcdef": "def"}, "code_tp.agents.snake.manual_control": {"fullname": "code_tp.agents.snake.manual_control", "modulename": "code_tp.agents.snake", "qualname": "manual_control", "type": "function", "doc": "<p>Permet de controler manuellement le serpent.</p>\n", "parameters": ["env"], "funcdef": "def"}, "code_tp.agents.target_value": {"fullname": "code_tp.agents.target_value", "modulename": "code_tp.agents.target_value", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.agents.target_value.TargetValueAgent": {"fullname": "code_tp.agents.target_value.TargetValueAgent", "modulename": "code_tp.agents.target_value", "qualname": "TargetValueAgent", "type": "class", "doc": "<p>Agent qui utilise une fonction de valeur diff\u00e9rente pour d\u00e9terminer la valeur cible\nlors d'un update.</p>\n"}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"fullname": "code_tp.agents.target_value.TargetValueAgent.__init__", "modulename": "code_tp.agents.target_value", "qualname": "TargetValueAgent.__init__", "type": "function", "doc": "<ul>\n<li><code>env</code>: Environnement gym dans lequel l'agent \u00e9volue</li>\n<li><code>value_function</code>: Instance d'une fonction de valeur (voir <code>code_tp/value_functions</code>)</li>\n<li><code>policy</code>: Instance d'une politique (voir <code>code_tp/policies</code>)</li>\n<li><code>gamma</code>: Taux de discount de l'agent. Doit \u00eatre compris entre 0 et 1</li>\n</ul>\n", "parameters": ["self", "env", "target_update", "args", "kwargs"], "funcdef": "def"}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"fullname": "code_tp.agents.target_value.TargetValueAgent.train_with_transition", "modulename": "code_tp.agents.target_value", "qualname": "TargetValueAgent.train_with_transition", "type": "function", "doc": "<p>Met \u00e0 jour l'agent suite \u00e0 une transition. Les noms des param\u00e8tres sont explicites.\nLe param\u00e8tre <code>infos</code>, rarement utilis\u00e9, fait partie des r\u00e9ponses standardis\u00e9es des\nenvironnements gym, et est donc inclus</p>\n", "parameters": ["self", "args", "kwargs"], "funcdef": "def"}, "code_tp.agents.target_value.TargetValueAgent.eval_state": {"fullname": "code_tp.agents.target_value.TargetValueAgent.eval_state", "modulename": "code_tp.agents.target_value", "qualname": "TargetValueAgent.eval_state", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.agents.target_value.TargetValueAgent.eval_state_batch": {"fullname": "code_tp.agents.target_value.TargetValueAgent.eval_state_batch", "modulename": "code_tp.agents.target_value", "qualname": "TargetValueAgent.eval_state_batch", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "states"], "funcdef": "def"}, "code_tp.environments": {"fullname": "code_tp.environments", "modulename": "code_tp.environments", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.environments.bandits": {"fullname": "code_tp.environments.bandits", "modulename": "code_tp.environments.bandits", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.environments.bandits.Bandits": {"fullname": "code_tp.environments.bandits.Bandits", "modulename": "code_tp.environments.bandits", "qualname": "Bandits", "type": "class", "doc": "<p>The main OpenAI Gym class. It encapsulates an environment with\narbitrary behind-the-scenes dynamics. An environment can be\npartially or fully observed.</p>\n\n<p>The main API methods that users of this class need to know are:</p>\n\n<pre><code>step\nreset\nrender\nclose\nseed\n</code></pre>\n\n<p>And set the following attributes:</p>\n\n<pre><code>action_space: The Space object corresponding to valid actions\nobservation_space: The Space object corresponding to valid observations\nreward_range: A tuple corresponding to the min and max possible rewards\n</code></pre>\n\n<p>Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.</p>\n\n<p>The methods are accessed publicly as \"step\", \"reset\", etc...</p>\n"}, "code_tp.environments.bandits.Bandits.__init__": {"fullname": "code_tp.environments.bandits.Bandits.__init__", "modulename": "code_tp.environments.bandits", "qualname": "Bandits.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.environments.bandits.Bandits.metadata": {"fullname": "code_tp.environments.bandits.Bandits.metadata", "modulename": "code_tp.environments.bandits", "qualname": "Bandits.metadata", "type": "variable", "doc": "<p></p>\n"}, "code_tp.environments.bandits.Bandits.K": {"fullname": "code_tp.environments.bandits.Bandits.K", "modulename": "code_tp.environments.bandits", "qualname": "Bandits.K", "type": "variable", "doc": "<p></p>\n"}, "code_tp.environments.bandits.Bandits.VAR_BETWEEN_SLOTS": {"fullname": "code_tp.environments.bandits.Bandits.VAR_BETWEEN_SLOTS", "modulename": "code_tp.environments.bandits", "qualname": "Bandits.VAR_BETWEEN_SLOTS", "type": "variable", "doc": "<p></p>\n"}, "code_tp.environments.bandits.Bandits.SLOT_VAR": {"fullname": "code_tp.environments.bandits.Bandits.SLOT_VAR", "modulename": "code_tp.environments.bandits", "qualname": "Bandits.SLOT_VAR", "type": "variable", "doc": "<p></p>\n"}, "code_tp.environments.bandits.Bandits.AVG_REWARD": {"fullname": "code_tp.environments.bandits.Bandits.AVG_REWARD", "modulename": "code_tp.environments.bandits", "qualname": "Bandits.AVG_REWARD", "type": "variable", "doc": "<p></p>\n"}, "code_tp.environments.bandits.Bandits.reset": {"fullname": "code_tp.environments.bandits.Bandits.reset", "modulename": "code_tp.environments.bandits", "qualname": "Bandits.reset", "type": "function", "doc": "<p>Resets the environment to an initial state and returns an initial\nobservation.</p>\n\n<p>Note that this function should not reset the environment's random\nnumber generator(s); random variables in the environment's state should\nbe sampled independently between multiple calls to <code>reset()</code>. In other\nwords, each call of <code>reset()</code> should yield an environment suitable for\na new episode, independent of previous episodes.</p>\n\n<p>Returns:\n    observation (object): the initial observation.</p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.environments.bandits.Bandits.step": {"fullname": "code_tp.environments.bandits.Bandits.step", "modulename": "code_tp.environments.bandits", "qualname": "Bandits.step", "type": "function", "doc": "<p>Run one timestep of the environment's dynamics. When end of\nepisode is reached, you are responsible for calling <code>reset()</code>\nto reset this environment's state.</p>\n\n<p>Accepts an action and returns a tuple (observation, reward, done, info).</p>\n\n<p>Args:\n    action (object): an action provided by the agent</p>\n\n<p>Returns:\n    observation (object): agent's observation of the current environment\n    reward (float) : amount of reward returned after previous action\n    done (bool): whether the episode has ended, in which case further step() calls will return undefined results\n    info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)</p>\n", "parameters": ["self", "action"], "funcdef": "def"}, "code_tp.environments.bandits.Bandits.render": {"fullname": "code_tp.environments.bandits.Bandits.render", "modulename": "code_tp.environments.bandits", "qualname": "Bandits.render", "type": "function", "doc": "<p>Renders the environment.</p>\n\n<p>The set of supported modes varies per environment. (And some\nenvironments do not support rendering at all.) By convention,\nif mode is:</p>\n\n<ul>\n<li>human: render to the current display or terminal and\nreturn nothing. Usually for human consumption.</li>\n<li>rgb_array: Return an numpy.ndarray with shape (x, y, 3),\nrepresenting RGB values for an x-by-y pixel image, suitable\nfor turning into a video.</li>\n<li>ansi: Return a string (str) or StringIO.StringIO containing a\nterminal-style text representation. The text can include newlines\nand ANSI escape sequences (e.g. for colors).</li>\n</ul>\n\n<p>Note:\n    Make sure that your class's metadata 'render.modes' key includes\n      the list of supported modes. It's recommended to call super()\n      in implementations to use the functionality of this method.</p>\n\n<p>Args:\n    mode (str): the mode to render with</p>\n\n<p>Example:</p>\n\n<p>class MyEnv(Env):\n    metadata = {'render.modes': ['human', 'rgb_array']}</p>\n\n<pre><code>def render(self, mode='human'):\n    if mode == 'rgb_array':\n        return np.array(...) # return RGB frame suitable for video\n    elif mode == 'human':\n        ... # pop up a window and render\n    else:\n        super(MyEnv, self).render(mode=mode) # just raise an exception\n</code></pre>\n", "parameters": ["self", "mode"], "funcdef": "def"}, "code_tp.environments.bandits.Bandits.close": {"fullname": "code_tp.environments.bandits.Bandits.close", "modulename": "code_tp.environments.bandits", "qualname": "Bandits.close", "type": "function", "doc": "<p>Override close in your subclass to perform any necessary cleanup.</p>\n\n<p>Environments will automatically close() themselves when\ngarbage collected or when the program exits.</p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.environments.gridworld": {"fullname": "code_tp.environments.gridworld", "modulename": "code_tp.environments.gridworld", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.environments.gridworld.LavaMaze": {"fullname": "code_tp.environments.gridworld.LavaMaze", "modulename": "code_tp.environments.gridworld", "qualname": "LavaMaze", "type": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n"}, "code_tp.environments.gridworld.LavaMaze.x": {"fullname": "code_tp.environments.gridworld.LavaMaze.x", "modulename": "code_tp.environments.gridworld", "qualname": "LavaMaze.x", "type": "variable", "doc": "<p></p>\n"}, "code_tp.environments.gridworld.CliffMaze": {"fullname": "code_tp.environments.gridworld.CliffMaze", "modulename": "code_tp.environments.gridworld", "qualname": "CliffMaze", "type": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n"}, "code_tp.environments.gridworld.CliffMaze.x": {"fullname": "code_tp.environments.gridworld.CliffMaze.x", "modulename": "code_tp.environments.gridworld", "qualname": "CliffMaze.x", "type": "variable", "doc": "<p></p>\n"}, "code_tp.environments.gridworld_utils": {"fullname": "code_tp.environments.gridworld_utils", "modulename": "code_tp.environments.gridworld_utils", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.environments.gridworld_utils.Maze": {"fullname": "code_tp.environments.gridworld_utils.Maze", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Maze", "type": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n"}, "code_tp.environments.gridworld_utils.Maze.x": {"fullname": "code_tp.environments.gridworld_utils.Maze.x", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Maze.x", "type": "variable", "doc": "<p></p>\n"}, "code_tp.environments.gridworld_utils.Maze.size": {"fullname": "code_tp.environments.gridworld_utils.Maze.size", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Maze.size", "type": "variable", "doc": "<p>Returns a pair of (height, width).</p>\n"}, "code_tp.environments.gridworld_utils.Maze.make_objects": {"fullname": "code_tp.environments.gridworld_utils.Maze.make_objects", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Maze.make_objects", "type": "function", "doc": "<p>Returns a list of defined objects.</p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.GenericMaze": {"fullname": "code_tp.environments.gridworld_utils.GenericMaze", "modulename": "code_tp.environments.gridworld_utils", "qualname": "GenericMaze", "type": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n"}, "code_tp.environments.gridworld_utils.GenericMaze.__init__": {"fullname": "code_tp.environments.gridworld_utils.GenericMaze.__init__", "modulename": "code_tp.environments.gridworld_utils", "qualname": "GenericMaze.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "x", "objects", "rewards_done"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"fullname": "code_tp.environments.gridworld_utils.GenericMaze.make_objects", "modulename": "code_tp.environments.gridworld_utils", "qualname": "GenericMaze.make_objects", "type": "function", "doc": "<p>Returns a list of defined objects.</p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.Env": {"fullname": "code_tp.environments.gridworld_utils.Env", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Env", "type": "class", "doc": "<p>The main OpenAI Gym class. It encapsulates an environment with\narbitrary behind-the-scenes dynamics. An environment can be\npartially or fully observed.</p>\n\n<p>The main API methods that users of this class need to know are:</p>\n\n<pre><code>step\nreset\nrender\nclose\nseed\n</code></pre>\n\n<p>And set the following attributes:</p>\n\n<pre><code>action_space: The Space object corresponding to valid actions\nobservation_space: The Space object corresponding to valid observations\nreward_range: A tuple corresponding to the min and max possible rewards\n</code></pre>\n\n<p>Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.</p>\n\n<p>The methods are accessed publicly as \"step\", \"reset\", etc...</p>\n"}, "code_tp.environments.gridworld_utils.Env.__init__": {"fullname": "code_tp.environments.gridworld_utils.Env.__init__", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Env.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.Env.maze": {"fullname": "code_tp.environments.gridworld_utils.Env.maze", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Env.maze", "type": "variable", "doc": "<p></p>\n"}, "code_tp.environments.gridworld_utils.Env.step": {"fullname": "code_tp.environments.gridworld_utils.Env.step", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Env.step", "type": "function", "doc": "<p>Run one timestep of the environment's dynamics. When end of\nepisode is reached, you are responsible for calling <code>reset()</code>\nto reset this environment's state.</p>\n\n<p>Accepts an action and returns a tuple (observation, reward, done, info).</p>\n\n<p>Args:\n    action (object): an action provided by the agent</p>\n\n<p>Returns:\n    observation (object): agent's observation of the current environment\n    reward (float) : amount of reward returned after previous action\n    done (bool): whether the episode has ended, in which case further step() calls will return undefined results\n    info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)</p>\n", "parameters": ["self", "action"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.Env.get_reward_and_done": {"fullname": "code_tp.environments.gridworld_utils.Env.get_reward_and_done", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Env.get_reward_and_done", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "new_position"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.Env.reset": {"fullname": "code_tp.environments.gridworld_utils.Env.reset", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Env.reset", "type": "function", "doc": "<p>Resets the environment to an initial state and returns an initial\nobservation.</p>\n\n<p>Note that this function should not reset the environment's random\nnumber generator(s); random variables in the environment's state should\nbe sampled independently between multiple calls to <code>reset()</code>. In other\nwords, each call of <code>reset()</code> should yield an environment suitable for\na new episode, independent of previous episodes.</p>\n\n<p>Returns:\n    observation (object): the initial observation.</p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.Env.get_image": {"fullname": "code_tp.environments.gridworld_utils.Env.get_image", "modulename": "code_tp.environments.gridworld_utils", "qualname": "Env.get_image", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.GenericEnv": {"fullname": "code_tp.environments.gridworld_utils.GenericEnv", "modulename": "code_tp.environments.gridworld_utils", "qualname": "GenericEnv", "type": "class", "doc": "<p>The main OpenAI Gym class. It encapsulates an environment with\narbitrary behind-the-scenes dynamics. An environment can be\npartially or fully observed.</p>\n\n<p>The main API methods that users of this class need to know are:</p>\n\n<pre><code>step\nreset\nrender\nclose\nseed\n</code></pre>\n\n<p>And set the following attributes:</p>\n\n<pre><code>action_space: The Space object corresponding to valid actions\nobservation_space: The Space object corresponding to valid observations\nreward_range: A tuple corresponding to the min and max possible rewards\n</code></pre>\n\n<p>Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.</p>\n\n<p>The methods are accessed publicly as \"step\", \"reset\", etc...</p>\n"}, "code_tp.environments.gridworld_utils.GenericEnv.default_reward": {"fullname": "code_tp.environments.gridworld_utils.GenericEnv.default_reward", "modulename": "code_tp.environments.gridworld_utils", "qualname": "GenericEnv.default_reward", "type": "variable", "doc": "<p></p>\n"}, "code_tp.environments.gridworld_utils.GenericEnv.get_reward_and_done": {"fullname": "code_tp.environments.gridworld_utils.GenericEnv.get_reward_and_done", "modulename": "code_tp.environments.gridworld_utils", "qualname": "GenericEnv.get_reward_and_done", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "new_position"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.register_env_from_maze": {"fullname": "code_tp.environments.gridworld_utils.register_env_from_maze", "modulename": "code_tp.environments.gridworld_utils", "qualname": "register_env_from_maze", "type": "function", "doc": "<p></p>\n", "parameters": ["this_maze", "name"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"fullname": "code_tp.environments.gridworld_utils.StochasticWrapper", "modulename": "code_tp.environments.gridworld_utils", "qualname": "StochasticWrapper", "type": "class", "doc": "<p>Wraps the environment to allow a modular transformation.</p>\n\n<p>This class is the base class for all wrappers. The subclass could override\nsome methods to change the behavior of the original environment without touching the\noriginal code.</p>\n\n<p>.. note::</p>\n\n<pre><code>Don't forget to call ``super().__init__(env)`` if the subclass overrides :meth:`__init__`.\n</code></pre>\n"}, "code_tp.environments.gridworld_utils.StochasticWrapper.__init__": {"fullname": "code_tp.environments.gridworld_utils.StochasticWrapper.__init__", "modulename": "code_tp.environments.gridworld_utils", "qualname": "StochasticWrapper.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "env", "stochasticity"], "funcdef": "def"}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"fullname": "code_tp.environments.gridworld_utils.StochasticWrapper.step", "modulename": "code_tp.environments.gridworld_utils", "qualname": "StochasticWrapper.step", "type": "function", "doc": "<p>Run one timestep of the environment's dynamics. When end of\nepisode is reached, you are responsible for calling <code>reset()</code>\nto reset this environment's state.</p>\n\n<p>Accepts an action and returns a tuple (observation, reward, done, info).</p>\n\n<p>Args:\n    action (object): an action provided by the agent</p>\n\n<p>Returns:\n    observation (object): agent's observation of the current environment\n    reward (float) : amount of reward returned after previous action\n    done (bool): whether the episode has ended, in which case further step() calls will return undefined results\n    info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)</p>\n", "parameters": ["self", "action"], "funcdef": "def"}, "code_tp.environments.snake_utils": {"fullname": "code_tp.environments.snake_utils", "modulename": "code_tp.environments.snake_utils", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.mazelab": {"fullname": "code_tp.mazelab", "modulename": "code_tp.mazelab", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.mazelab.color_style": {"fullname": "code_tp.mazelab.color_style", "modulename": "code_tp.mazelab.color_style", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.mazelab.color_style.DeepMindColor": {"fullname": "code_tp.mazelab.color_style.DeepMindColor", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor", "type": "class", "doc": "<p>DeepMindColor()</p>\n"}, "code_tp.mazelab.color_style.DeepMindColor.__init__": {"fullname": "code_tp.mazelab.color_style.DeepMindColor.__init__", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.mazelab.color_style.DeepMindColor.obstacle": {"fullname": "code_tp.mazelab.color_style.DeepMindColor.obstacle", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor.obstacle", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.color_style.DeepMindColor.free": {"fullname": "code_tp.mazelab.color_style.DeepMindColor.free", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor.free", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.color_style.DeepMindColor.agent": {"fullname": "code_tp.mazelab.color_style.DeepMindColor.agent", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor.agent", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.color_style.DeepMindColor.goal": {"fullname": "code_tp.mazelab.color_style.DeepMindColor.goal", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor.goal", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.color_style.DeepMindColor.button": {"fullname": "code_tp.mazelab.color_style.DeepMindColor.button", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor.button", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.color_style.DeepMindColor.interruption": {"fullname": "code_tp.mazelab.color_style.DeepMindColor.interruption", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor.interruption", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.color_style.DeepMindColor.box": {"fullname": "code_tp.mazelab.color_style.DeepMindColor.box", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor.box", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.color_style.DeepMindColor.lava": {"fullname": "code_tp.mazelab.color_style.DeepMindColor.lava", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor.lava", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.color_style.DeepMindColor.water": {"fullname": "code_tp.mazelab.color_style.DeepMindColor.water", "modulename": "code_tp.mazelab.color_style", "qualname": "DeepMindColor.water", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.env": {"fullname": "code_tp.mazelab.env", "modulename": "code_tp.mazelab.env", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.mazelab.env.BaseEnv": {"fullname": "code_tp.mazelab.env.BaseEnv", "modulename": "code_tp.mazelab.env", "qualname": "BaseEnv", "type": "class", "doc": "<p>The main OpenAI Gym class. It encapsulates an environment with\narbitrary behind-the-scenes dynamics. An environment can be\npartially or fully observed.</p>\n\n<p>The main API methods that users of this class need to know are:</p>\n\n<pre><code>step\nreset\nrender\nclose\nseed\n</code></pre>\n\n<p>And set the following attributes:</p>\n\n<pre><code>action_space: The Space object corresponding to valid actions\nobservation_space: The Space object corresponding to valid observations\nreward_range: A tuple corresponding to the min and max possible rewards\n</code></pre>\n\n<p>Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.</p>\n\n<p>The methods are accessed publicly as \"step\", \"reset\", etc...</p>\n"}, "code_tp.mazelab.env.BaseEnv.metadata": {"fullname": "code_tp.mazelab.env.BaseEnv.metadata", "modulename": "code_tp.mazelab.env", "qualname": "BaseEnv.metadata", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.env.BaseEnv.reward_range": {"fullname": "code_tp.mazelab.env.BaseEnv.reward_range", "modulename": "code_tp.mazelab.env", "qualname": "BaseEnv.reward_range", "type": "variable", "doc": "<p></p>\n"}, "code_tp.mazelab.env.BaseEnv.step": {"fullname": "code_tp.mazelab.env.BaseEnv.step", "modulename": "code_tp.mazelab.env", "qualname": "BaseEnv.step", "type": "function", "doc": "<p>Run one timestep of the environment's dynamics. When end of\nepisode is reached, you are responsible for calling <code>reset()</code>\nto reset this environment's state.</p>\n\n<p>Accepts an action and returns a tuple (observation, reward, done, info).</p>\n\n<p>Args:\n    action (object): an action provided by the agent</p>\n\n<p>Returns:\n    observation (object): agent's observation of the current environment\n    reward (float) : amount of reward returned after previous action\n    done (bool): whether the episode has ended, in which case further step() calls will return undefined results\n    info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)</p>\n", "parameters": ["self", "action"], "funcdef": "def"}, "code_tp.mazelab.env.BaseEnv.seed": {"fullname": "code_tp.mazelab.env.BaseEnv.seed", "modulename": "code_tp.mazelab.env", "qualname": "BaseEnv.seed", "type": "function", "doc": "<p>Sets the seed for this env's random number generator(s).</p>\n\n<p>Note:\n    Some environments use multiple pseudorandom number generators.\n    We want to capture all such seeds used in order to ensure that\n    there aren't accidental correlations between multiple generators.</p>\n\n<p>Returns:\n    list<bigint>: Returns the list of seeds used in this env's random\n      number generators. The first value in the list should be the\n      \"main\" seed, or the value which a reproducer should pass to\n      'seed'. Often, the main seed equals the provided 'seed', but\n      this won't be true if seed=None, for example.</p>\n", "parameters": ["self", "seed"], "funcdef": "def"}, "code_tp.mazelab.env.BaseEnv.reset": {"fullname": "code_tp.mazelab.env.BaseEnv.reset", "modulename": "code_tp.mazelab.env", "qualname": "BaseEnv.reset", "type": "function", "doc": "<p>Resets the environment to an initial state and returns an initial\nobservation.</p>\n\n<p>Note that this function should not reset the environment's random\nnumber generator(s); random variables in the environment's state should\nbe sampled independently between multiple calls to <code>reset()</code>. In other\nwords, each call of <code>reset()</code> should yield an environment suitable for\na new episode, independent of previous episodes.</p>\n\n<p>Returns:\n    observation (object): the initial observation.</p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.mazelab.env.BaseEnv.get_image": {"fullname": "code_tp.mazelab.env.BaseEnv.get_image", "modulename": "code_tp.mazelab.env", "qualname": "BaseEnv.get_image", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.mazelab.env.BaseEnv.render": {"fullname": "code_tp.mazelab.env.BaseEnv.render", "modulename": "code_tp.mazelab.env", "qualname": "BaseEnv.render", "type": "function", "doc": "<p>Renders the environment.</p>\n\n<p>The set of supported modes varies per environment. (And some\nenvironments do not support rendering at all.) By convention,\nif mode is:</p>\n\n<ul>\n<li>human: render to the current display or terminal and\nreturn nothing. Usually for human consumption.</li>\n<li>rgb_array: Return an numpy.ndarray with shape (x, y, 3),\nrepresenting RGB values for an x-by-y pixel image, suitable\nfor turning into a video.</li>\n<li>ansi: Return a string (str) or StringIO.StringIO containing a\nterminal-style text representation. The text can include newlines\nand ANSI escape sequences (e.g. for colors).</li>\n</ul>\n\n<p>Note:\n    Make sure that your class's metadata 'render.modes' key includes\n      the list of supported modes. It's recommended to call super()\n      in implementations to use the functionality of this method.</p>\n\n<p>Args:\n    mode (str): the mode to render with</p>\n\n<p>Example:</p>\n\n<p>class MyEnv(Env):\n    metadata = {'render.modes': ['human', 'rgb_array']}</p>\n\n<pre><code>def render(self, mode='human'):\n    if mode == 'rgb_array':\n        return np.array(...) # return RGB frame suitable for video\n    elif mode == 'human':\n        ... # pop up a window and render\n    else:\n        super(MyEnv, self).render(mode=mode) # just raise an exception\n</code></pre>\n", "parameters": ["self", "mode", "max_width"], "funcdef": "def"}, "code_tp.mazelab.env.BaseEnv.close": {"fullname": "code_tp.mazelab.env.BaseEnv.close", "modulename": "code_tp.mazelab.env", "qualname": "BaseEnv.close", "type": "function", "doc": "<p>Override close in your subclass to perform any necessary cleanup.</p>\n\n<p>Environments will automatically close() themselves when\ngarbage collected or when the program exits.</p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.mazelab.maze": {"fullname": "code_tp.mazelab.maze", "modulename": "code_tp.mazelab.maze", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.mazelab.maze.BaseMaze": {"fullname": "code_tp.mazelab.maze.BaseMaze", "modulename": "code_tp.mazelab.maze", "qualname": "BaseMaze", "type": "class", "doc": "<p>Helper class that provides a standard way to create an ABC using\ninheritance.</p>\n"}, "code_tp.mazelab.maze.BaseMaze.size": {"fullname": "code_tp.mazelab.maze.BaseMaze.size", "modulename": "code_tp.mazelab.maze", "qualname": "BaseMaze.size", "type": "variable", "doc": "<p>Returns a pair of (height, width).</p>\n"}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"fullname": "code_tp.mazelab.maze.BaseMaze.make_objects", "modulename": "code_tp.mazelab.maze", "qualname": "BaseMaze.make_objects", "type": "function", "doc": "<p>Returns a list of defined objects.</p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.mazelab.maze.BaseMaze.to_name": {"fullname": "code_tp.mazelab.maze.BaseMaze.to_name", "modulename": "code_tp.mazelab.maze", "qualname": "BaseMaze.to_name", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.mazelab.maze.BaseMaze.to_value": {"fullname": "code_tp.mazelab.maze.BaseMaze.to_value", "modulename": "code_tp.mazelab.maze", "qualname": "BaseMaze.to_value", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.mazelab.maze.BaseMaze.to_rgb": {"fullname": "code_tp.mazelab.maze.BaseMaze.to_rgb", "modulename": "code_tp.mazelab.maze", "qualname": "BaseMaze.to_rgb", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.mazelab.maze.BaseMaze.to_impassable": {"fullname": "code_tp.mazelab.maze.BaseMaze.to_impassable", "modulename": "code_tp.mazelab.maze", "qualname": "BaseMaze.to_impassable", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.mazelab.motion": {"fullname": "code_tp.mazelab.motion", "modulename": "code_tp.mazelab.motion", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.mazelab.motion.VonNeumannMotion": {"fullname": "code_tp.mazelab.motion.VonNeumannMotion", "modulename": "code_tp.mazelab.motion", "qualname": "VonNeumannMotion", "type": "class", "doc": "<p>VonNeumannMotion(north, south, west, east)</p>\n"}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"fullname": "code_tp.mazelab.motion.VonNeumannMotion.__init__", "modulename": "code_tp.mazelab.motion", "qualname": "VonNeumannMotion.__init__", "type": "function", "doc": "<p>Create new instance of VonNeumannMotion(north, south, west, east)</p>\n", "parameters": ["_cls", "north", "south", "west", "east"], "funcdef": "def"}, "code_tp.mazelab.motion.VonNeumannMotion.north": {"fullname": "code_tp.mazelab.motion.VonNeumannMotion.north", "modulename": "code_tp.mazelab.motion", "qualname": "VonNeumannMotion.north", "type": "variable", "doc": "<p>Alias for field number 0</p>\n"}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"fullname": "code_tp.mazelab.motion.VonNeumannMotion.south", "modulename": "code_tp.mazelab.motion", "qualname": "VonNeumannMotion.south", "type": "variable", "doc": "<p>Alias for field number 1</p>\n"}, "code_tp.mazelab.motion.VonNeumannMotion.west": {"fullname": "code_tp.mazelab.motion.VonNeumannMotion.west", "modulename": "code_tp.mazelab.motion", "qualname": "VonNeumannMotion.west", "type": "variable", "doc": "<p>Alias for field number 2</p>\n"}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"fullname": "code_tp.mazelab.motion.VonNeumannMotion.east", "modulename": "code_tp.mazelab.motion", "qualname": "VonNeumannMotion.east", "type": "variable", "doc": "<p>Alias for field number 3</p>\n"}, "code_tp.mazelab.motion.MooreMotion": {"fullname": "code_tp.mazelab.motion.MooreMotion", "modulename": "code_tp.mazelab.motion", "qualname": "MooreMotion", "type": "class", "doc": "<p>MooreMotion(north, south, west, east, northwest, northeast, southwest, southeast)</p>\n"}, "code_tp.mazelab.motion.MooreMotion.__init__": {"fullname": "code_tp.mazelab.motion.MooreMotion.__init__", "modulename": "code_tp.mazelab.motion", "qualname": "MooreMotion.__init__", "type": "function", "doc": "<p>Create new instance of MooreMotion(north, south, west, east, northwest, northeast, southwest, southeast)</p>\n", "parameters": ["_cls", "north", "south", "west", "east", "northwest", "northeast", "southwest", "southeast"], "funcdef": "def"}, "code_tp.mazelab.motion.MooreMotion.north": {"fullname": "code_tp.mazelab.motion.MooreMotion.north", "modulename": "code_tp.mazelab.motion", "qualname": "MooreMotion.north", "type": "variable", "doc": "<p>Alias for field number 0</p>\n"}, "code_tp.mazelab.motion.MooreMotion.south": {"fullname": "code_tp.mazelab.motion.MooreMotion.south", "modulename": "code_tp.mazelab.motion", "qualname": "MooreMotion.south", "type": "variable", "doc": "<p>Alias for field number 1</p>\n"}, "code_tp.mazelab.motion.MooreMotion.west": {"fullname": "code_tp.mazelab.motion.MooreMotion.west", "modulename": "code_tp.mazelab.motion", "qualname": "MooreMotion.west", "type": "variable", "doc": "<p>Alias for field number 2</p>\n"}, "code_tp.mazelab.motion.MooreMotion.east": {"fullname": "code_tp.mazelab.motion.MooreMotion.east", "modulename": "code_tp.mazelab.motion", "qualname": "MooreMotion.east", "type": "variable", "doc": "<p>Alias for field number 3</p>\n"}, "code_tp.mazelab.motion.MooreMotion.northwest": {"fullname": "code_tp.mazelab.motion.MooreMotion.northwest", "modulename": "code_tp.mazelab.motion", "qualname": "MooreMotion.northwest", "type": "variable", "doc": "<p>Alias for field number 4</p>\n"}, "code_tp.mazelab.motion.MooreMotion.northeast": {"fullname": "code_tp.mazelab.motion.MooreMotion.northeast", "modulename": "code_tp.mazelab.motion", "qualname": "MooreMotion.northeast", "type": "variable", "doc": "<p>Alias for field number 5</p>\n"}, "code_tp.mazelab.motion.MooreMotion.southwest": {"fullname": "code_tp.mazelab.motion.MooreMotion.southwest", "modulename": "code_tp.mazelab.motion", "qualname": "MooreMotion.southwest", "type": "variable", "doc": "<p>Alias for field number 6</p>\n"}, "code_tp.mazelab.motion.MooreMotion.southeast": {"fullname": "code_tp.mazelab.motion.MooreMotion.southeast", "modulename": "code_tp.mazelab.motion", "qualname": "MooreMotion.southeast", "type": "variable", "doc": "<p>Alias for field number 7</p>\n"}, "code_tp.mazelab.object": {"fullname": "code_tp.mazelab.object", "modulename": "code_tp.mazelab.object", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.mazelab.object.Object": {"fullname": "code_tp.mazelab.object.Object", "modulename": "code_tp.mazelab.object", "qualname": "Object", "type": "class", "doc": "<p>Defines an object with some of its properties. </p>\n\n<p>An object can be an obstacle, free space or food etc. It can also have properties like impassable, positions.</p>\n"}, "code_tp.mazelab.object.Object.__init__": {"fullname": "code_tp.mazelab.object.Object.__init__", "modulename": "code_tp.mazelab.object", "qualname": "Object.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "name", "value", "rgb", "impassable", "positions"], "funcdef": "def"}, "code_tp.policies": {"fullname": "code_tp.policies", "modulename": "code_tp.policies", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.policies.greedy": {"fullname": "code_tp.policies.greedy", "modulename": "code_tp.policies.greedy", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.policies.greedy.RandomPolicy": {"fullname": "code_tp.policies.greedy.RandomPolicy", "modulename": "code_tp.policies.greedy", "qualname": "RandomPolicy", "type": "class", "doc": "<p>Politique al\u00e9atoire, sert de classe de base \u00e0 toutes les politiques.\nUn agent suivant cette politique est \u00e9quivalent \u00e0 un <code>RandomAgent</code> dans son comportement</p>\n"}, "code_tp.policies.greedy.RandomPolicy.__init__": {"fullname": "code_tp.policies.greedy.RandomPolicy.__init__", "modulename": "code_tp.policies.greedy", "qualname": "RandomPolicy.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "value_function"], "funcdef": "def"}, "code_tp.policies.greedy.RandomPolicy.test": {"fullname": "code_tp.policies.greedy.RandomPolicy.test", "modulename": "code_tp.policies.greedy", "qualname": "RandomPolicy.test", "type": "function", "doc": "<p>Prend un \u00e9tat en argument, retourne une action.\nUtilis\u00e9e durant les \u00e9pisodes d'\u00e9valuation, le comportement par d\u00e9faut est d'appliquer\nla politique d\u00e9finie dans <code>__call__</code></p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.policies.greedy.RandomPolicy.update": {"fullname": "code_tp.policies.greedy.RandomPolicy.update", "modulename": "code_tp.policies.greedy", "qualname": "RandomPolicy.update", "type": "function", "doc": "<p>M\u00e9thode appel\u00e9e \u00e0 la fin de chaque pas de temps pour \u00e9ventuellement mettre\n\u00e0 jour la politique</p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.policies.greedy.GreedyQPolicy": {"fullname": "code_tp.policies.greedy.GreedyQPolicy", "modulename": "code_tp.policies.greedy", "qualname": "GreedyQPolicy", "type": "class", "doc": "<p>Impl\u00e9mente la politique <em>greedy</em> sur une fonction de valeur</p>\n"}, "code_tp.policies.greedy.GreedyQPolicy.__init__": {"fullname": "code_tp.policies.greedy.GreedyQPolicy.__init__", "modulename": "code_tp.policies.greedy", "qualname": "GreedyQPolicy.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "value_function"], "funcdef": "def"}, "code_tp.policies.greedy.EGreedyPolicy": {"fullname": "code_tp.policies.greedy.EGreedyPolicy", "modulename": "code_tp.policies.greedy", "qualname": "EGreedyPolicy", "type": "class", "doc": "<p>Politique al\u00e9atoire, sert de classe de base \u00e0 toutes les politiques.\nUn agent suivant cette politique est \u00e9quivalent \u00e0 un <code>RandomAgent</code> dans son comportement</p>\n"}, "code_tp.policies.greedy.EGreedyPolicy.__init__": {"fullname": "code_tp.policies.greedy.EGreedyPolicy.__init__", "modulename": "code_tp.policies.greedy", "qualname": "EGreedyPolicy.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "value_function", "greedy_policy_class", "epsilon", "epsilon_decay", "epsilon_min", "epsilon_test"], "funcdef": "def"}, "code_tp.policies.greedy.EGreedyPolicy.test": {"fullname": "code_tp.policies.greedy.EGreedyPolicy.test", "modulename": "code_tp.policies.greedy", "qualname": "EGreedyPolicy.test", "type": "function", "doc": "<p>Prend un \u00e9tat en argument, retourne une action.\nUtilis\u00e9e durant les \u00e9pisodes d'\u00e9valuation, le comportement par d\u00e9faut est d'appliquer\nla politique d\u00e9finie dans <code>__call__</code></p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.policies.greedy.EGreedyPolicy.update_epsilon": {"fullname": "code_tp.policies.greedy.EGreedyPolicy.update_epsilon", "modulename": "code_tp.policies.greedy", "qualname": "EGreedyPolicy.update_epsilon", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.policies.greedy.EGreedyPolicy.update": {"fullname": "code_tp.policies.greedy.EGreedyPolicy.update", "modulename": "code_tp.policies.greedy", "qualname": "EGreedyPolicy.update", "type": "function", "doc": "<p>M\u00e9thode appel\u00e9e \u00e0 la fin de chaque pas de temps pour \u00e9ventuellement mettre\n\u00e0 jour la politique</p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"fullname": "code_tp.policies.greedy.CosineEGreedyPolicy", "modulename": "code_tp.policies.greedy", "qualname": "CosineEGreedyPolicy", "type": "class", "doc": "<p>Fait varier epsilon comme un cosinus du pas de temps</p>\n\n<p>R\u00e9utilise les param\u00e8tres de <code>EGreedyPolicy</code> pour d\u00e9finir le cosinus :</p>\n\n<ul>\n<li><code>T</code>: P\u00e9riode du cosinus (en pas de temps)</li>\n<li><code>epsilon</code>: Valeur max d'epsilon</li>\n<li><code>epsilon_min</code>: Valeur max d'epsilon</li>\n<li><code>epsilon_decay</code>: D\u00e9croissance de epsilon_max</li>\n</ul>\n\n<p>$epsilon = (epsilon_{max}-epsilon_{min})/2 \\cos(\frac{2\\Pi}{epsilon_{decay}} t) + epsilon_{min}$</p>\n"}, "code_tp.policies.greedy.CosineEGreedyPolicy.__init__": {"fullname": "code_tp.policies.greedy.CosineEGreedyPolicy.__init__", "modulename": "code_tp.policies.greedy", "qualname": "CosineEGreedyPolicy.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "T", "epsilon_max_final", "args", "kwargs"], "funcdef": "def"}, "code_tp.policies.greedy.CosineEGreedyPolicy.update_epsilon": {"fullname": "code_tp.policies.greedy.CosineEGreedyPolicy.update_epsilon", "modulename": "code_tp.policies.greedy", "qualname": "CosineEGreedyPolicy.update_epsilon", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.policies.softmax_sampling": {"fullname": "code_tp.policies.softmax_sampling", "modulename": "code_tp.policies.softmax_sampling", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"fullname": "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy", "modulename": "code_tp.policies.softmax_sampling", "qualname": "SoftmaxSamplingPolicy", "type": "class", "doc": "<p>Pareil que la politique epsilon-greedy, mais l'action est tir\u00e9e avec la probabilit\u00e9 :</p>\n\n<p>p(a) = softmax(5<em>(1-epsilon)</em>Q(s,a))</p>\n\n<p>epsilon=1 &lt;=&gt; Choix compl\u00e8tement \u00e9quiprobable parmi les actions\nepsilon=0 &lt;=&gt; Politique greedy</p>\n"}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy.__init__": {"fullname": "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy.__init__", "modulename": "code_tp.policies.softmax_sampling", "qualname": "SoftmaxSamplingPolicy.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "args", "kwargs"], "funcdef": "def"}, "code_tp.utils": {"fullname": "code_tp.utils", "modulename": "code_tp.utils", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.utils.isnotebook": {"fullname": "code_tp.utils.isnotebook", "modulename": "code_tp.utils", "qualname": "isnotebook", "type": "function", "doc": "<p></p>\n", "parameters": [], "funcdef": "def"}, "code_tp.utils.logging": {"fullname": "code_tp.utils.logging", "modulename": "code_tp.utils.logging", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.utils.logging.add_args_as_info": {"fullname": "code_tp.utils.logging.add_args_as_info", "modulename": "code_tp.utils.logging", "qualname": "add_args_as_info", "type": "function", "doc": "<p></p>\n", "parameters": ["func"], "funcdef": "def"}, "code_tp.value_functions": {"fullname": "code_tp.value_functions", "modulename": "code_tp.value_functions", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.value_functions.base": {"fullname": "code_tp.value_functions.base", "modulename": "code_tp.value_functions.base", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.value_functions.base.enum_discrete": {"fullname": "code_tp.value_functions.base.enum_discrete", "modulename": "code_tp.value_functions.base", "qualname": "enum_discrete", "type": "function", "doc": "<p>Fonction utilitaire pour obtenir un it\u00e9rateur sur les actions d'un espace <code>gym.spaces.Discrete</code></p>\n", "parameters": ["space"], "funcdef": "def"}, "code_tp.value_functions.base.ValueFunction": {"fullname": "code_tp.value_functions.base.ValueFunction", "modulename": "code_tp.value_functions.base", "qualname": "ValueFunction", "type": "class", "doc": "<p>Classe de base des fonctions de valeur de type $v(s)$</p>\n"}, "code_tp.value_functions.base.ValueFunction.__init__": {"fullname": "code_tp.value_functions.base.ValueFunction.__init__", "modulename": "code_tp.value_functions.base", "qualname": "ValueFunction.__init__", "type": "function", "doc": "<ul>\n<li><code>env</code>: Environnement sur lequel porte la fonction de valeur. Est utilis\u00e9 uniquement pour\n     d\u00e9terminer les espaces des \u00e9tats et des actions.</li>\n<li><code>lr</code>: Taux d'apprentissage</li>\n<li><code>lr_decay</code>: D\u00e9croissance du taux d'apprentissage : \u00e0 chaque pas de temps, le taux\n          d'apprentissage est multipli\u00e9 par <code>1-lr_decay</code></li>\n<li><code>lr_min</code>: Taux d'apprentissage minimum, \u00e0 partir duquel celui-ci de d\u00e9croit plus</li>\n</ul>\n", "parameters": ["self", "env", "lr", "lr_decay", "lr_min"], "funcdef": "def"}, "code_tp.value_functions.base.ValueFunction.call_batch": {"fullname": "code_tp.value_functions.base.ValueFunction.call_batch", "modulename": "code_tp.value_functions.base", "qualname": "ValueFunction.call_batch", "type": "function", "doc": "<p>Permet d'\u00e9valuer un batch d'\u00e9tats. Simple boucle qui sera surcharg\u00e9e pour tirer partie\nde l'\u00e9valuation par batch des fonctions neurales</p>\n", "parameters": ["self", "states"], "funcdef": "def"}, "code_tp.value_functions.base.ValueFunction.update": {"fullname": "code_tp.value_functions.base.ValueFunction.update", "modulename": "code_tp.value_functions.base", "qualname": "ValueFunction.update", "type": "function", "doc": "<p>Met \u00e0 jour la fonction de valeur \u00e0 partir d'une transition exp\u00e9riment\u00e9e.\nMaintient \u00e9galement les param\u00e8tres de l'entrainement.\nPour cette classe de base, s'occupe uniquement de la d\u00e9croissance du taux d'apprentissage.</p>\n\n<ul>\n<li><code>state</code>: \u00e9tat de d\u00e9part d'une transition</li>\n<li><code>action</code>: action effectu\u00e9e depuis l'\u00e9tat <code>state</code></li>\n<li><code>target_value</code>: valeur cible, d\u00e9termin\u00e9e par l'agent selon son algorithme d'apprentissage</li>\n</ul>\n", "parameters": ["self", "state", "action", "target_value"], "funcdef": "def"}, "code_tp.value_functions.base.ValueFunction.update_batch": {"fullname": "code_tp.value_functions.base.ValueFunction.update_batch", "modulename": "code_tp.value_functions.base", "qualname": "ValueFunction.update_batch", "type": "function", "doc": "<p>M\u00e9thode mettant \u00e0 jour l'agent sur un <em>batch</em> de transitions. Simple boucle pour appeler\n<code>self.update</code> par d\u00e9faut. Est utile principalement pour les agents \u00e0 <em>replay buffer</em>.</p>\n\n<p>M\u00e9thode qui sera surcharg\u00e9e avec les fonctions de valeur neurales, qui prennent en charge\nl'\u00e9valuation par batch.</p>\n", "parameters": ["self", "states", "actions", "target_values"], "funcdef": "def"}, "code_tp.value_functions.base.ValueFunction.export_f": {"fullname": "code_tp.value_functions.base.ValueFunction.export_f", "modulename": "code_tp.value_functions.base", "qualname": "ValueFunction.export_f", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.value_functions.base.ValueFunction.import_f": {"fullname": "code_tp.value_functions.base.ValueFunction.import_f", "modulename": "code_tp.value_functions.base", "qualname": "ValueFunction.import_f", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "d"], "funcdef": "def"}, "code_tp.value_functions.base.ValueFunction.clone": {"fullname": "code_tp.value_functions.base.ValueFunction.clone", "modulename": "code_tp.value_functions.base", "qualname": "ValueFunction.clone", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.value_functions.base.DiscreteQFunction": {"fullname": "code_tp.value_functions.base.DiscreteQFunction", "modulename": "code_tp.value_functions.base", "qualname": "DiscreteQFunction", "type": "class", "doc": "<p>Classe de base pour les fonctions de valeur de type $q(s,a)$ dans les espaces d'actions discrets</p>\n"}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"fullname": "code_tp.value_functions.base.DiscreteQFunction.__init__", "modulename": "code_tp.value_functions.base", "qualname": "DiscreteQFunction.__init__", "type": "function", "doc": "<ul>\n<li><code>env</code>: Environnement sur lequel porte la fonction de valeur. Est utilis\u00e9 uniquement pour\n     d\u00e9terminer les espaces des \u00e9tats et des actions.</li>\n<li><code>lr</code>: Taux d'apprentissage</li>\n<li><code>lr_decay</code>: D\u00e9croissance du taux d'apprentissage : \u00e0 chaque pas de temps, le taux\n          d'apprentissage est multipli\u00e9 par <code>1-lr_decay</code></li>\n<li><code>lr_min</code>: Taux d'apprentissage minimum, \u00e0 partir duquel celui-ci de d\u00e9croit plus</li>\n</ul>\n", "parameters": ["self", "env", "args", "kwargs"], "funcdef": "def"}, "code_tp.value_functions.base.DiscreteQFunction.enum_actions": {"fullname": "code_tp.value_functions.base.DiscreteQFunction.enum_actions", "modulename": "code_tp.value_functions.base", "qualname": "DiscreteQFunction.enum_actions", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"fullname": "code_tp.value_functions.base.DiscreteQFunction.from_state", "modulename": "code_tp.value_functions.base", "qualname": "DiscreteQFunction.from_state", "type": "function", "doc": "<p>Prend un \u00e9tat et renvoit un dictionnaire <code>action : valeur</code> pour cet \u00e9tat</p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.value_functions.base.DiscreteQFunction.from_state_batch": {"fullname": "code_tp.value_functions.base.DiscreteQFunction.from_state_batch", "modulename": "code_tp.value_functions.base", "qualname": "DiscreteQFunction.from_state_batch", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "states"], "funcdef": "def"}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state": {"fullname": "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state", "modulename": "code_tp.value_functions.base", "qualname": "DiscreteQFunction.best_action_value_from_state", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state_batch": {"fullname": "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state_batch", "modulename": "code_tp.value_functions.base", "qualname": "DiscreteQFunction.best_action_value_from_state_batch", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "states"], "funcdef": "def"}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"fullname": "code_tp.value_functions.base.DiscreteQFunction.call_batch", "modulename": "code_tp.value_functions.base", "qualname": "DiscreteQFunction.call_batch", "type": "function", "doc": "<p>Permet d'\u00e9valuer un batch d'\u00e9tats. Simple boucle qui sera surcharg\u00e9e pour tirer partie\nde l'\u00e9valuation par batch des fonctions neurales</p>\n", "parameters": ["self", "states", "actions"], "funcdef": "def"}, "code_tp.value_functions.linear": {"fullname": "code_tp.value_functions.linear", "modulename": "code_tp.value_functions.linear", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.value_functions.linear.LinearQValue": {"fullname": "code_tp.value_functions.linear.LinearQValue", "modulename": "code_tp.value_functions.linear", "qualname": "LinearQValue", "type": "class", "doc": "<p>Classe de base pour les fonctions de valeur de type $q(s,a)$ dans les espaces d'actions discrets</p>\n"}, "code_tp.value_functions.linear.LinearQValue.__init__": {"fullname": "code_tp.value_functions.linear.LinearQValue.__init__", "modulename": "code_tp.value_functions.linear", "qualname": "LinearQValue.__init__", "type": "function", "doc": "<ul>\n<li><code>env</code>: Environnement sur lequel porte la fonction de valeur. Est utilis\u00e9 uniquement pour\n     d\u00e9terminer les espaces des \u00e9tats et des actions.</li>\n<li><code>lr</code>: Taux d'apprentissage</li>\n<li><code>lr_decay</code>: D\u00e9croissance du taux d'apprentissage : \u00e0 chaque pas de temps, le taux\n          d'apprentissage est multipli\u00e9 par <code>1-lr_decay</code></li>\n<li><code>lr_min</code>: Taux d'apprentissage minimum, \u00e0 partir duquel celui-ci de d\u00e9croit plus</li>\n</ul>\n", "parameters": ["self", "env", "default_value", "args", "kwargs"], "funcdef": "def"}, "code_tp.value_functions.linear.LinearQValue.add_bias": {"fullname": "code_tp.value_functions.linear.LinearQValue.add_bias", "modulename": "code_tp.value_functions.linear", "qualname": "LinearQValue.add_bias", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.value_functions.linear.LinearQValue.from_state": {"fullname": "code_tp.value_functions.linear.LinearQValue.from_state", "modulename": "code_tp.value_functions.linear", "qualname": "LinearQValue.from_state", "type": "function", "doc": "<p>Prend un \u00e9tat et renvoit un dictionnaire <code>action : valeur</code> pour cet \u00e9tat</p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.value_functions.linear.LinearQValue.update": {"fullname": "code_tp.value_functions.linear.LinearQValue.update", "modulename": "code_tp.value_functions.linear", "qualname": "LinearQValue.update", "type": "function", "doc": "<p>Met \u00e0 jour la fonction de valeur \u00e0 partir d'une transition exp\u00e9riment\u00e9e.\nMaintient \u00e9galement les param\u00e8tres de l'entrainement.\nPour cette classe de base, s'occupe uniquement de la d\u00e9croissance du taux d'apprentissage.</p>\n\n<ul>\n<li><code>state</code>: \u00e9tat de d\u00e9part d'une transition</li>\n<li><code>action</code>: action effectu\u00e9e depuis l'\u00e9tat <code>state</code></li>\n<li><code>target_value</code>: valeur cible, d\u00e9termin\u00e9e par l'agent selon son algorithme d'apprentissage</li>\n</ul>\n", "parameters": ["self", "state", "action", "target_value"], "funcdef": "def"}, "code_tp.value_functions.linear.LinearQValue.export_f": {"fullname": "code_tp.value_functions.linear.LinearQValue.export_f", "modulename": "code_tp.value_functions.linear", "qualname": "LinearQValue.export_f", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.value_functions.linear.LinearQValue.import_f": {"fullname": "code_tp.value_functions.linear.LinearQValue.import_f", "modulename": "code_tp.value_functions.linear", "qualname": "LinearQValue.import_f", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "d"], "funcdef": "def"}, "code_tp.value_functions.neural": {"fullname": "code_tp.value_functions.neural", "modulename": "code_tp.value_functions.neural", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.value_functions.neural.ConvolutionalNN": {"fullname": "code_tp.value_functions.neural.ConvolutionalNN", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalNN", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call :meth:<code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n"}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"fullname": "code_tp.value_functions.neural.ConvolutionalNN.__init__", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalNN.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "parameters": ["self", "img_shape", "n_actions", "n_filters", "kernel_size", "stride", "padding", "dilation", "hidden_linear", "activation"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"fullname": "code_tp.value_functions.neural.ConvolutionalNN.forward", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalNN.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<p>.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:<code>Module</code> instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them.</p>\n", "parameters": ["self", "x"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction", "type": "class", "doc": "<p>Classe de base pour les fonctions de valeur de type $q(s,a)$ dans les espaces d'actions discrets</p>\n"}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction.__init__", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction.__init__", "type": "function", "doc": "<ul>\n<li><code>env</code>: Environnement sur lequel porte la fonction de valeur. Est utilis\u00e9 uniquement pour\n     d\u00e9terminer les espaces des \u00e9tats et des actions.</li>\n<li><code>lr</code>: Taux d'apprentissage</li>\n<li><code>lr_decay</code>: D\u00e9croissance du taux d'apprentissage : \u00e0 chaque pas de temps, le taux\n          d'apprentissage est multipli\u00e9 par <code>1-lr_decay</code></li>\n<li><code>lr_min</code>: Taux d'apprentissage minimum, \u00e0 partir duquel celui-ci de d\u00e9croit plus</li>\n</ul>\n", "parameters": ["self", "env", "nn_args", "args", "kwargs"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction.from_state", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction.from_state", "type": "function", "doc": "<p>Prend un \u00e9tat et renvoit un dictionnaire <code>action : valeur</code> pour cet \u00e9tat</p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state_batch": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction.from_state_batch", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction.from_state_batch", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "states"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction.call_batch", "type": "function", "doc": "<p>Permet d'\u00e9valuer un batch d'\u00e9tats. Simple boucle qui sera surcharg\u00e9e pour tirer partie\nde l'\u00e9valuation par batch des fonctions neurales</p>\n", "parameters": ["self", "states", "actions"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction.update", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction.update", "type": "function", "doc": "<p>Met \u00e0 jour la fonction de valeur \u00e0 partir d'une transition exp\u00e9riment\u00e9e.\nMaintient \u00e9galement les param\u00e8tres de l'entrainement.\nPour cette classe de base, s'occupe uniquement de la d\u00e9croissance du taux d'apprentissage.</p>\n\n<ul>\n<li><code>state</code>: \u00e9tat de d\u00e9part d'une transition</li>\n<li><code>action</code>: action effectu\u00e9e depuis l'\u00e9tat <code>state</code></li>\n<li><code>target_value</code>: valeur cible, d\u00e9termin\u00e9e par l'agent selon son algorithme d'apprentissage</li>\n</ul>\n", "parameters": ["self", "state", "action", "target_value"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction.update_batch", "type": "function", "doc": "<p>M\u00e9thode mettant \u00e0 jour l'agent sur un <em>batch</em> de transitions. Simple boucle pour appeler\n<code>self.update</code> par d\u00e9faut. Est utile principalement pour les agents \u00e0 <em>replay buffer</em>.</p>\n\n<p>M\u00e9thode qui sera surcharg\u00e9e avec les fonctions de valeur neurales, qui prennent en charge\nl'\u00e9valuation par batch.</p>\n", "parameters": ["self", "states", "actions", "target_values"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction.best_action_value_from_state", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state_batch": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state_batch", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction.best_action_value_from_state_batch", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "states"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalQFunction.export_f": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction.export_f", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction.export_f", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.value_functions.neural.ConvolutionalQFunction.import_f": {"fullname": "code_tp.value_functions.neural.ConvolutionalQFunction.import_f", "modulename": "code_tp.value_functions.neural", "qualname": "ConvolutionalQFunction.import_f", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "d"], "funcdef": "def"}, "code_tp.value_functions.tabular": {"fullname": "code_tp.value_functions.tabular", "modulename": "code_tp.value_functions.tabular", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.value_functions.tabular.TabularQValue": {"fullname": "code_tp.value_functions.tabular.TabularQValue", "modulename": "code_tp.value_functions.tabular", "qualname": "TabularQValue", "type": "class", "doc": "<p>Fonction de valeur tabulaire</p>\n"}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"fullname": "code_tp.value_functions.tabular.TabularQValue.__init__", "modulename": "code_tp.value_functions.tabular", "qualname": "TabularQValue.__init__", "type": "function", "doc": "<ul>\n<li><code>default_value</code>: Valeur d'initialisation <em>a priori</em> des \u00e9tats-actions</li>\n</ul>\n", "parameters": ["self", "env", "default_value", "args", "kwargs"], "funcdef": "def"}, "code_tp.value_functions.tabular.TabularQValue.create_state": {"fullname": "code_tp.value_functions.tabular.TabularQValue.create_state", "modulename": "code_tp.value_functions.tabular", "qualname": "TabularQValue.create_state", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"fullname": "code_tp.value_functions.tabular.TabularQValue.from_state", "modulename": "code_tp.value_functions.tabular", "qualname": "TabularQValue.from_state", "type": "function", "doc": "<p>Prend un \u00e9tat et renvoit un dictionnaire <code>action : valeur</code> pour cet \u00e9tat</p>\n", "parameters": ["self", "state"], "funcdef": "def"}, "code_tp.value_functions.tabular.TabularQValue.update": {"fullname": "code_tp.value_functions.tabular.TabularQValue.update", "modulename": "code_tp.value_functions.tabular", "qualname": "TabularQValue.update", "type": "function", "doc": "<p>Met \u00e0 jour la fonction de valeur \u00e0 partir d'une transition exp\u00e9riment\u00e9e.\nMaintient \u00e9galement les param\u00e8tres de l'entrainement.\nPour cette classe de base, s'occupe uniquement de la d\u00e9croissance du taux d'apprentissage.</p>\n\n<ul>\n<li><code>state</code>: \u00e9tat de d\u00e9part d'une transition</li>\n<li><code>action</code>: action effectu\u00e9e depuis l'\u00e9tat <code>state</code></li>\n<li><code>target_value</code>: valeur cible, d\u00e9termin\u00e9e par l'agent selon son algorithme d'apprentissage</li>\n</ul>\n", "parameters": ["self", "state", "action", "target_value"], "funcdef": "def"}, "code_tp.value_functions.tabular.TabularQValue.show_known_states": {"fullname": "code_tp.value_functions.tabular.TabularQValue.show_known_states", "modulename": "code_tp.value_functions.tabular", "qualname": "TabularQValue.show_known_states", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "save_dir"], "funcdef": "def"}, "code_tp.value_functions.tabular.TabularQValue.export_f": {"fullname": "code_tp.value_functions.tabular.TabularQValue.export_f", "modulename": "code_tp.value_functions.tabular", "qualname": "TabularQValue.export_f", "type": "function", "doc": "<p></p>\n", "parameters": ["self"], "funcdef": "def"}, "code_tp.value_functions.tabular.TabularQValue.import_f": {"fullname": "code_tp.value_functions.tabular.TabularQValue.import_f", "modulename": "code_tp.value_functions.tabular", "qualname": "TabularQValue.import_f", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "d"], "funcdef": "def"}, "code_tp.wrappers": {"fullname": "code_tp.wrappers", "modulename": "code_tp.wrappers", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.wrappers.utils": {"fullname": "code_tp.wrappers.utils", "modulename": "code_tp.wrappers.utils", "qualname": "", "type": "module", "doc": "<p></p>\n"}, "code_tp.wrappers.utils.LogScaleObs": {"fullname": "code_tp.wrappers.utils.LogScaleObs", "modulename": "code_tp.wrappers.utils", "qualname": "LogScaleObs", "type": "class", "doc": "<p>Transforme les observations afin de dilater les valeurs proches de zero</p>\n"}, "code_tp.wrappers.utils.LogScaleObs.__init__": {"fullname": "code_tp.wrappers.utils.LogScaleObs.__init__", "modulename": "code_tp.wrappers.utils", "qualname": "LogScaleObs.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "env", "args", "kwargs"], "funcdef": "def"}, "code_tp.wrappers.utils.LogScaleObs.t": {"fullname": "code_tp.wrappers.utils.LogScaleObs.t", "modulename": "code_tp.wrappers.utils", "qualname": "LogScaleObs.t", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "x"], "funcdef": "def"}, "code_tp.wrappers.utils.LogScaleObs.observation": {"fullname": "code_tp.wrappers.utils.LogScaleObs.observation", "modulename": "code_tp.wrappers.utils", "qualname": "LogScaleObs.observation", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "s"], "funcdef": "def"}, "code_tp.wrappers.utils.TabularObservation": {"fullname": "code_tp.wrappers.utils.TabularObservation", "modulename": "code_tp.wrappers.utils", "qualname": "TabularObservation", "type": "class", "doc": "<p>Transforme les observations de type <code>gym.spaces.Box</code> en <code>gym.spaces.Discrete</code> en d\u00e9coupant les\nintervals de valeurs en tranches \u00e9gales.</p>\n"}, "code_tp.wrappers.utils.TabularObservation.__init__": {"fullname": "code_tp.wrappers.utils.TabularObservation.__init__", "modulename": "code_tp.wrappers.utils", "qualname": "TabularObservation.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "env", "n_levels", "feature_wrapper", "args", "kwargs"], "funcdef": "def"}, "code_tp.wrappers.utils.TabularObservation.observation": {"fullname": "code_tp.wrappers.utils.TabularObservation.observation", "modulename": "code_tp.wrappers.utils", "qualname": "TabularObservation.observation", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "s"], "funcdef": "def"}, "code_tp.wrappers.utils.BoredomWrapper": {"fullname": "code_tp.wrappers.utils.BoredomWrapper", "modulename": "code_tp.wrappers.utils", "qualname": "BoredomWrapper", "type": "class", "doc": "<p>Ajoute une faible punition \u00e0 tous les pas de temps.</p>\n"}, "code_tp.wrappers.utils.BoredomWrapper.__init__": {"fullname": "code_tp.wrappers.utils.BoredomWrapper.__init__", "modulename": "code_tp.wrappers.utils", "qualname": "BoredomWrapper.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "env", "reward_per_step"], "funcdef": "def"}, "code_tp.wrappers.utils.BoredomWrapper.reward": {"fullname": "code_tp.wrappers.utils.BoredomWrapper.reward", "modulename": "code_tp.wrappers.utils", "qualname": "BoredomWrapper.reward", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "reward"], "funcdef": "def"}, "code_tp.wrappers.utils.TimeToChannels": {"fullname": "code_tp.wrappers.utils.TimeToChannels", "modulename": "code_tp.wrappers.utils", "qualname": "TimeToChannels", "type": "class", "doc": "<p>R\u00e9arrange les observations pour int\u00e9grer le canal temporel dans les canaux de couleur</p>\n"}, "code_tp.wrappers.utils.TimeToChannels.__init__": {"fullname": "code_tp.wrappers.utils.TimeToChannels.__init__", "modulename": "code_tp.wrappers.utils", "qualname": "TimeToChannels.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "env", "args", "kwargs"], "funcdef": "def"}, "code_tp.wrappers.utils.TimeToChannels.observation": {"fullname": "code_tp.wrappers.utils.TimeToChannels.observation", "modulename": "code_tp.wrappers.utils", "qualname": "TimeToChannels.observation", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "observation"], "funcdef": "def"}}, "docInfo": {"code_tp": {"qualname": 0, "fullname": 1, "doc": 0}, "code_tp.dict_to_dirname": {"qualname": 1, "fullname": 2, "doc": 0}, "code_tp.class_and_args_to_dirname": {"qualname": 1, "fullname": 2, "doc": 0}, "code_tp.date_dirname": {"qualname": 1, "fullname": 2, "doc": 0}, "code_tp.create_agent_and_env": {"qualname": 1, "fullname": 2, "doc": 3}, "code_tp.create_agent_from_env": {"qualname": 1, "fullname": 2, "doc": 28}, "code_tp.agents": {"qualname": 0, "fullname": 2, "doc": 0}, "code_tp.agents.base": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.agents.base.Agent": {"qualname": 1, "fullname": 4, "doc": 7}, "code_tp.agents.base.Agent.__init__": {"qualname": 2, "fullname": 5, "doc": 37}, "code_tp.agents.base.Agent.log_data": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.base.Agent.select_action": {"qualname": 2, "fullname": 5, "doc": 8}, "code_tp.agents.base.Agent.train_with_transition": {"qualname": 2, "fullname": 5, "doc": 29}, "code_tp.agents.base.Agent.step": {"qualname": 2, "fullname": 5, "doc": 18}, "code_tp.agents.base.Agent.run_episode": {"qualname": 2, "fullname": 5, "doc": 21}, "code_tp.agents.base.Agent.run_n_episodes": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.base.Agent.train": {"qualname": 2, "fullname": 5, "doc": 56}, "code_tp.agents.base.Agent.episode_end": {"qualname": 2, "fullname": 5, "doc": 17}, "code_tp.agents.base.Agent.plot_stats": {"qualname": 2, "fullname": 5, "doc": 20}, "code_tp.agents.base.RandomAgent": {"qualname": 1, "fullname": 4, "doc": 10}, "code_tp.agents.base.RandomAgent.select_action": {"qualname": 2, "fullname": 5, "doc": 8}, "code_tp.agents.base.RandomAgent.train_with_transition": {"qualname": 2, "fullname": 5, "doc": 29}, "code_tp.agents.base.QLearningAgent": {"qualname": 1, "fullname": 4, "doc": 5}, "code_tp.agents.base.QLearningAgent.__init__": {"qualname": 2, "fullname": 5, "doc": 34}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"qualname": 2, "fullname": 5, "doc": 29}, "code_tp.agents.base.QLearningAgent.eval_state": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.base.QLearningAgent.eval_state_batch": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.base.QLearningAgent.target_value_from_state": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.base.QLearningAgent.target_value_from_state_batch": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.base.QLearningAgent.select_action": {"qualname": 2, "fullname": 5, "doc": 8}, "code_tp.agents.base.QLearningAgent.plot_stats": {"qualname": 2, "fullname": 5, "doc": 20}, "code_tp.agents.base.SARSAAgent": {"qualname": 1, "fullname": 4, "doc": 5}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"qualname": 2, "fullname": 5, "doc": 29}, "code_tp.agents.gridworld": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"qualname": 1, "fullname": 4, "doc": 22}, "code_tp.agents.gridworld.GridworldTabularValueAgent.show_values": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"qualname": 2, "fullname": 5, "doc": 56}, "code_tp.agents.replay_buffer": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.agents.replay_buffer.ReplayBuffer": {"qualname": 1, "fullname": 4, "doc": 0}, "code_tp.agents.replay_buffer.ReplayBuffer.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.replay_buffer.ReplayBuffer.ready": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.replay_buffer.ReplayBuffer.store": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.replay_buffer.ReplayBuffer.sample": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"qualname": 1, "fullname": 4, "doc": 7}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"qualname": 2, "fullname": 5, "doc": 37}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"qualname": 2, "fullname": 5, "doc": 29}, "code_tp.agents.snake": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.agents.snake.AddDirectionToSnakeState": {"qualname": 1, "fullname": 4, "doc": 12}, "code_tp.agents.snake.AddDirectionToSnakeState.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.snake.AddDirectionToSnakeState.observation": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.snake.SnakeFeatureObservation": {"qualname": 1, "fullname": 4, "doc": 16}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"qualname": 2, "fullname": 5, "doc": 37}, "code_tp.agents.snake.SnakeFeatureObservation.OC": {"qualname": 2, "fullname": 5, "doc": 5}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"qualname": 2, "fullname": 5, "doc": 12}, "code_tp.agents.snake.make_feature_snake_env": {"qualname": 1, "fullname": 4, "doc": 32}, "code_tp.agents.snake.make_tabular_snake_env": {"qualname": 1, "fullname": 4, "doc": 42}, "code_tp.agents.snake.manual_control": {"qualname": 1, "fullname": 4, "doc": 6}, "code_tp.agents.target_value": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.agents.target_value.TargetValueAgent": {"qualname": 1, "fullname": 4, "doc": 16}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"qualname": 2, "fullname": 5, "doc": 34}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"qualname": 2, "fullname": 5, "doc": 29}, "code_tp.agents.target_value.TargetValueAgent.eval_state": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.agents.target_value.TargetValueAgent.eval_state_batch": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments": {"qualname": 0, "fullname": 2, "doc": 0}, "code_tp.environments.bandits": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.environments.bandits.Bandits": {"qualname": 1, "fullname": 4, "doc": 66}, "code_tp.environments.bandits.Bandits.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.bandits.Bandits.metadata": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.bandits.Bandits.K": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.bandits.Bandits.VAR_BETWEEN_SLOTS": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.bandits.Bandits.SLOT_VAR": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.bandits.Bandits.AVG_REWARD": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.bandits.Bandits.reset": {"qualname": 2, "fullname": 5, "doc": 41}, "code_tp.environments.bandits.Bandits.step": {"qualname": 2, "fullname": 5, "doc": 64}, "code_tp.environments.bandits.Bandits.render": {"qualname": 2, "fullname": 5, "doc": 119}, "code_tp.environments.bandits.Bandits.close": {"qualname": 2, "fullname": 5, "doc": 14}, "code_tp.environments.gridworld": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.environments.gridworld.LavaMaze": {"qualname": 1, "fullname": 4, "doc": 9}, "code_tp.environments.gridworld.LavaMaze.x": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld.CliffMaze": {"qualname": 1, "fullname": 4, "doc": 9}, "code_tp.environments.gridworld.CliffMaze.x": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld_utils": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.environments.gridworld_utils.Maze": {"qualname": 1, "fullname": 4, "doc": 9}, "code_tp.environments.gridworld_utils.Maze.x": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld_utils.Maze.size": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.environments.gridworld_utils.Maze.make_objects": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.environments.gridworld_utils.GenericMaze": {"qualname": 1, "fullname": 4, "doc": 9}, "code_tp.environments.gridworld_utils.GenericMaze.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.environments.gridworld_utils.Env": {"qualname": 1, "fullname": 4, "doc": 66}, "code_tp.environments.gridworld_utils.Env.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld_utils.Env.maze": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld_utils.Env.step": {"qualname": 2, "fullname": 5, "doc": 64}, "code_tp.environments.gridworld_utils.Env.get_reward_and_done": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld_utils.Env.reset": {"qualname": 2, "fullname": 5, "doc": 41}, "code_tp.environments.gridworld_utils.Env.get_image": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld_utils.GenericEnv": {"qualname": 1, "fullname": 4, "doc": 66}, "code_tp.environments.gridworld_utils.GenericEnv.default_reward": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld_utils.GenericEnv.get_reward_and_done": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld_utils.register_env_from_maze": {"qualname": 1, "fullname": 4, "doc": 0}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"qualname": 1, "fullname": 4, "doc": 29}, "code_tp.environments.gridworld_utils.StochasticWrapper.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"qualname": 2, "fullname": 5, "doc": 64}, "code_tp.environments.snake_utils": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.mazelab": {"qualname": 0, "fullname": 2, "doc": 0}, "code_tp.mazelab.color_style": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.mazelab.color_style.DeepMindColor": {"qualname": 1, "fullname": 4, "doc": 1}, "code_tp.mazelab.color_style.DeepMindColor.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.color_style.DeepMindColor.obstacle": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.color_style.DeepMindColor.free": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.color_style.DeepMindColor.agent": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.color_style.DeepMindColor.goal": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.color_style.DeepMindColor.button": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.color_style.DeepMindColor.interruption": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.color_style.DeepMindColor.box": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.color_style.DeepMindColor.lava": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.color_style.DeepMindColor.water": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.env": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.mazelab.env.BaseEnv": {"qualname": 1, "fullname": 4, "doc": 66}, "code_tp.mazelab.env.BaseEnv.metadata": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.env.BaseEnv.reward_range": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.env.BaseEnv.step": {"qualname": 2, "fullname": 5, "doc": 64}, "code_tp.mazelab.env.BaseEnv.seed": {"qualname": 2, "fullname": 5, "doc": 54}, "code_tp.mazelab.env.BaseEnv.reset": {"qualname": 2, "fullname": 5, "doc": 41}, "code_tp.mazelab.env.BaseEnv.get_image": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.env.BaseEnv.render": {"qualname": 2, "fullname": 5, "doc": 119}, "code_tp.mazelab.env.BaseEnv.close": {"qualname": 2, "fullname": 5, "doc": 14}, "code_tp.mazelab.maze": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.mazelab.maze.BaseMaze": {"qualname": 1, "fullname": 4, "doc": 9}, "code_tp.mazelab.maze.BaseMaze.size": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.maze.BaseMaze.to_name": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.maze.BaseMaze.to_value": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.maze.BaseMaze.to_rgb": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.maze.BaseMaze.to_impassable": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.mazelab.motion": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.mazelab.motion.VonNeumannMotion": {"qualname": 1, "fullname": 4, "doc": 4}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"qualname": 2, "fullname": 5, "doc": 7}, "code_tp.mazelab.motion.VonNeumannMotion.north": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.VonNeumannMotion.west": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.MooreMotion": {"qualname": 1, "fullname": 4, "doc": 8}, "code_tp.mazelab.motion.MooreMotion.__init__": {"qualname": 2, "fullname": 5, "doc": 11}, "code_tp.mazelab.motion.MooreMotion.north": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.MooreMotion.south": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.MooreMotion.west": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.MooreMotion.east": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.MooreMotion.northwest": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.MooreMotion.northeast": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.MooreMotion.southwest": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.motion.MooreMotion.southeast": {"qualname": 2, "fullname": 5, "doc": 4}, "code_tp.mazelab.object": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.mazelab.object.Object": {"qualname": 1, "fullname": 4, "doc": 12}, "code_tp.mazelab.object.Object.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.policies": {"qualname": 0, "fullname": 2, "doc": 0}, "code_tp.policies.greedy": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.policies.greedy.RandomPolicy": {"qualname": 1, "fullname": 4, "doc": 22}, "code_tp.policies.greedy.RandomPolicy.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.policies.greedy.RandomPolicy.test": {"qualname": 2, "fullname": 5, "doc": 24}, "code_tp.policies.greedy.RandomPolicy.update": {"qualname": 2, "fullname": 5, "doc": 15}, "code_tp.policies.greedy.GreedyQPolicy": {"qualname": 1, "fullname": 4, "doc": 9}, "code_tp.policies.greedy.GreedyQPolicy.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.policies.greedy.EGreedyPolicy": {"qualname": 1, "fullname": 4, "doc": 22}, "code_tp.policies.greedy.EGreedyPolicy.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.policies.greedy.EGreedyPolicy.test": {"qualname": 2, "fullname": 5, "doc": 24}, "code_tp.policies.greedy.EGreedyPolicy.update_epsilon": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.policies.greedy.EGreedyPolicy.update": {"qualname": 2, "fullname": 5, "doc": 15}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"qualname": 1, "fullname": 4, "doc": 46}, "code_tp.policies.greedy.CosineEGreedyPolicy.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.policies.greedy.CosineEGreedyPolicy.update_epsilon": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.policies.softmax_sampling": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"qualname": 1, "fullname": 4, "doc": 32}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.utils": {"qualname": 0, "fullname": 2, "doc": 0}, "code_tp.utils.isnotebook": {"qualname": 1, "fullname": 3, "doc": 0}, "code_tp.utils.logging": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.utils.logging.add_args_as_info": {"qualname": 1, "fullname": 4, "doc": 0}, "code_tp.value_functions": {"qualname": 0, "fullname": 2, "doc": 0}, "code_tp.value_functions.base": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.value_functions.base.enum_discrete": {"qualname": 1, "fullname": 4, "doc": 14}, "code_tp.value_functions.base.ValueFunction": {"qualname": 1, "fullname": 4, "doc": 10}, "code_tp.value_functions.base.ValueFunction.__init__": {"qualname": 2, "fullname": 5, "doc": 52}, "code_tp.value_functions.base.ValueFunction.call_batch": {"qualname": 2, "fullname": 5, "doc": 20}, "code_tp.value_functions.base.ValueFunction.update": {"qualname": 2, "fullname": 5, "doc": 51}, "code_tp.value_functions.base.ValueFunction.update_batch": {"qualname": 2, "fullname": 5, "doc": 42}, "code_tp.value_functions.base.ValueFunction.export_f": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.base.ValueFunction.import_f": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.base.ValueFunction.clone": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.base.DiscreteQFunction": {"qualname": 1, "fullname": 4, "doc": 16}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"qualname": 2, "fullname": 5, "doc": 52}, "code_tp.value_functions.base.DiscreteQFunction.enum_actions": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"qualname": 2, "fullname": 5, "doc": 12}, "code_tp.value_functions.base.DiscreteQFunction.from_state_batch": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state_batch": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"qualname": 2, "fullname": 5, "doc": 20}, "code_tp.value_functions.linear": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.value_functions.linear.LinearQValue": {"qualname": 1, "fullname": 4, "doc": 16}, "code_tp.value_functions.linear.LinearQValue.__init__": {"qualname": 2, "fullname": 5, "doc": 52}, "code_tp.value_functions.linear.LinearQValue.add_bias": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.linear.LinearQValue.from_state": {"qualname": 2, "fullname": 5, "doc": 12}, "code_tp.value_functions.linear.LinearQValue.update": {"qualname": 2, "fullname": 5, "doc": 51}, "code_tp.value_functions.linear.LinearQValue.export_f": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.linear.LinearQValue.import_f": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.neural": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.value_functions.neural.ConvolutionalNN": {"qualname": 1, "fullname": 4, "doc": 80}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"qualname": 2, "fullname": 5, "doc": 9}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"qualname": 2, "fullname": 5, "doc": 31}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"qualname": 1, "fullname": 4, "doc": 16}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"qualname": 2, "fullname": 5, "doc": 52}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"qualname": 2, "fullname": 5, "doc": 12}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state_batch": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"qualname": 2, "fullname": 5, "doc": 20}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"qualname": 2, "fullname": 5, "doc": 51}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"qualname": 2, "fullname": 5, "doc": 42}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state_batch": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.neural.ConvolutionalQFunction.export_f": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.neural.ConvolutionalQFunction.import_f": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.tabular": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.value_functions.tabular.TabularQValue": {"qualname": 1, "fullname": 4, "doc": 4}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"qualname": 2, "fullname": 5, "doc": 7}, "code_tp.value_functions.tabular.TabularQValue.create_state": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"qualname": 2, "fullname": 5, "doc": 12}, "code_tp.value_functions.tabular.TabularQValue.update": {"qualname": 2, "fullname": 5, "doc": 51}, "code_tp.value_functions.tabular.TabularQValue.show_known_states": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.tabular.TabularQValue.export_f": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.value_functions.tabular.TabularQValue.import_f": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.wrappers": {"qualname": 0, "fullname": 2, "doc": 0}, "code_tp.wrappers.utils": {"qualname": 0, "fullname": 3, "doc": 0}, "code_tp.wrappers.utils.LogScaleObs": {"qualname": 1, "fullname": 4, "doc": 11}, "code_tp.wrappers.utils.LogScaleObs.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.wrappers.utils.LogScaleObs.t": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.wrappers.utils.LogScaleObs.observation": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.wrappers.utils.TabularObservation": {"qualname": 1, "fullname": 4, "doc": 21}, "code_tp.wrappers.utils.TabularObservation.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.wrappers.utils.TabularObservation.observation": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.wrappers.utils.BoredomWrapper": {"qualname": 1, "fullname": 4, "doc": 9}, "code_tp.wrappers.utils.BoredomWrapper.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.wrappers.utils.BoredomWrapper.reward": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.wrappers.utils.TimeToChannels": {"qualname": 1, "fullname": 4, "doc": 13}, "code_tp.wrappers.utils.TimeToChannels.__init__": {"qualname": 2, "fullname": 5, "doc": 0}, "code_tp.wrappers.utils.TimeToChannels.observation": {"qualname": 2, "fullname": 5, "doc": 0}}, "length": 244, "save": true}, "index": {"qualname": {"root": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.dict_to_dirname": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.enum_actions": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}}, "df": 8}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.date_dirname": {"tf": 1}}, "df": 1}}}}}}}}}}, "e": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.gridworld_utils.GenericEnv.default_reward": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.mazelab.color_style.DeepMindColor": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.__init__": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.obstacle": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.free": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.agent": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.goal": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.button": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.interruption": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.box": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.lava": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.water": {"tf": 1}}, "df": 11}}}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.class_and_args_to_dirname": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 2}}, "n": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.value_functions.base.ValueFunction.clone": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze.x": {"tf": 1}}, "df": 2}}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.create_agent_and_env": {"tf": 1}}, "df": 1}}}}}}}, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.tabular.TabularQValue.create_state": {"tf": 1}}, "df": 1}}}}}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.update_epsilon": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 3}}, "q": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.export_f": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.import_f": {"tf": 1}}, "df": 11}}}}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}}, "df": 3}}}}}}}}}}, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.log_data": {"tf": 1}, "code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.run_n_episodes": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.agent": {"tf": 1}}, "df": 12}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.__init__": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.observation": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "o": {"docs": {"code_tp.utils.logging.add_args_as_info": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.value_functions.linear.LinearQValue.add_bias": {"tf": 1}}, "df": 1}}}}}}, "v": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits.AVG_REWARD": {"tf": 1}}, "df": 1}}}}}}}}}}, "_": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "_": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.environments.bandits.Bandits.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.__init__": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.__init__": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}, "code_tp.mazelab.object.Object.__init__": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.__init__": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.__init__": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.__init__": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.__init__": {"tf": 1}}, "df": 30}}}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.agents.base.Agent.log_data": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {"code_tp.wrappers.utils.LogScaleObs": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.__init__": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.t": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.observation": {"tf": 1}}, "df": 4}}}}}}}}}, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.lava": {"tf": 1}}, "df": 1, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze.x": {"tf": 1}}, "df": 2}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.add_bias": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.export_f": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.import_f": {"tf": 1}}, "df": 7}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}}, "df": 3}}}}}}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 5}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.replay_buffer.ReplayBuffer.store": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.base.SARSAAgent": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}}, "df": 2}}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.replay_buffer.ReplayBuffer.sample": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent.show_values": {"tf": 1}}, "df": 1}}}}, "k": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.tabular.TabularQValue.show_known_states": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits.SLOT_VAR": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}}, "df": 2}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}}, "df": 2, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}}, "df": 1}}}}}}}, "f": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}}}}}}, "t": {"docs": {"code_tp.wrappers.utils.LogScaleObs.t": {"tf": 1}}, "df": 1, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 2, "_": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6}}}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.QLearningAgent.target_value_from_state": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.agents.base.QLearningAgent.target_value_from_state_batch": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state_batch": {"tf": 1}}, "df": 5}}}}}}}}}}}, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.value_functions.tabular.TabularQValue": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.create_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.show_known_states": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.export_f": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.import_f": {"tf": 1}}, "df": 8}}}}}, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.wrappers.utils.TabularObservation": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.__init__": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.observation": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.mazelab.maze.BaseMaze.to_name": {"tf": 1}}, "df": 1}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.mazelab.maze.BaseMaze.to_value": {"tf": 1}}, "df": 1}}}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "b": {"docs": {"code_tp.mazelab.maze.BaseMaze.to_rgb": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.mazelab.maze.BaseMaze.to_impassable": {"tf": 1}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 2}}}, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.wrappers.utils.TimeToChannels": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.__init__": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.observation": {"tf": 1}}, "df": 3}}}}}}}}}}}}}, "r": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}}, "df": 1}}}}}}, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.run_n_episodes": {"tf": 1}}, "df": 1}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}}, "df": 3}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}}, "df": 4}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.agents.replay_buffer.ReplayBuffer": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.ready": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.store": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.sample": {"tf": 1}}, "df": 5, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.agents.replay_buffer.ReplayBuffer.ready": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 3}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.environments.gridworld_utils.register_env_from_maze": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.wrappers.utils.BoredomWrapper.reward": {"tf": 1}}, "df": 1, "_": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.mazelab.env.BaseEnv.reward_range": {"tf": 1}}, "df": 1}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.episode_end": {"tf": 1}}, "df": 1}}}}}}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.QLearningAgent.eval_state": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state": {"tf": 1}}, "df": 2, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.agents.base.QLearningAgent.eval_state_batch": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state_batch": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.maze": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.get_reward_and_done": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.get_image": {"tf": 1}}, "df": 7}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.enum_discrete": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.enum_actions": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}}, "df": 2}}}, "g": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update_epsilon": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}}, "df": 5}}}}}}}}}}}}, "x": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.value_functions.base.ValueFunction.export_f": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.export_f": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.export_f": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.export_f": {"tf": 1}}, "df": 4}}}}}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 2}}}}}}}}}, "q": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.base.QLearningAgent": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.eval_state": {"tf": 1}, "code_tp.agents.base.QLearningAgent.eval_state_batch": {"tf": 1}, "code_tp.agents.base.QLearningAgent.target_value_from_state": {"tf": 1}, "code_tp.agents.base.QLearningAgent.target_value_from_state_batch": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 9}}}}}}}}}}}, "g": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.show_values": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.default_reward": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.get_reward_and_done": {"tf": 1}}, "df": 3}}}}}}}}, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.gridworld_utils.Env.get_reward_and_done": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.get_reward_and_done": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.environments.gridworld_utils.Env.get_image": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.get_image": {"tf": 1}}, "df": 2}}}}}}}, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.goal": {"tf": 1}}, "df": 1}}}}, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.AddDirectionToSnakeState.observation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.observation": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.observation": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.observation": {"tf": 1}}, "df": 5}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.obstacle": {"tf": 1}}, "df": 1}}}}}, "j": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.object.Object": {"tf": 1}, "code_tp.mazelab.object.Object.__init__": {"tf": 1}}, "df": 2}}}}}, "c": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}}, "df": 1}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "j": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}}, "df": 3}}}}}}}}}, "n": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.manual_control": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "z": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.x": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.maze": {"tf": 1}}, "df": 5}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.environments.bandits.Bandits.metadata": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.metadata": {"tf": 1}}, "df": 2}}}}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}}, "df": 10}}}}}}}}, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits.__init__": {"tf": 1}, "code_tp.environments.bandits.Bandits.metadata": {"tf": 1}, "code_tp.environments.bandits.Bandits.K": {"tf": 1}, "code_tp.environments.bandits.Bandits.VAR_BETWEEN_SLOTS": {"tf": 1}, "code_tp.environments.bandits.Bandits.SLOT_VAR": {"tf": 1}, "code_tp.environments.bandits.Bandits.AVG_REWARD": {"tf": 1}, "code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.bandits.Bandits.close": {"tf": 1}}, "df": 11}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.metadata": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reward_range": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.get_image": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 9}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.mazelab.maze.BaseMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_name": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_value": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_rgb": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_impassable": {"tf": 1}}, "df": 7}}}}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.button": {"tf": 1}}, "df": 1}}}}}, "o": {"docs": {}, "df": 0, "x": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.box": {"tf": 1}}, "df": 1}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.__init__": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.reward": {"tf": 1}}, "df": 3}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state": {"tf": 1}}, "df": 2, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state_batch": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "k": {"docs": {"code_tp.environments.bandits.Bandits.K": {"tf": 1}}, "df": 1}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.VAR_BETWEEN_SLOTS": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.ValueFunction": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.export_f": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.import_f": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.clone": {"tf": 1}}, "df": 8}}}}}}}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}}, "df": 6}}}}}}}}}}}}}, "x": {"docs": {"code_tp.environments.gridworld.LavaMaze.x": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze.x": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.x": {"tf": 1}}, "df": 3}, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.free": {"tf": 1}}, "df": 1}}, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}}, "df": 4, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state_batch": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.interruption": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {"code_tp.utils.isnotebook": {"tf": 1}}, "df": 1}}}}}}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.value_functions.base.ValueFunction.import_f": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.import_f": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.import_f": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.import_f": {"tf": 1}}, "df": 4}}}}}}}}, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.water": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}}, "df": 2}}}}, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}}, "df": 2, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}}, "df": 1}}}}}}}}}, "u": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 6, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.policies.greedy.EGreedyPolicy.update_epsilon": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.update_epsilon": {"tf": 1}}, "df": 2}}}}}}}, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}, "fullname": {"root": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {"code_tp": {"tf": 1}, "code_tp.dict_to_dirname": {"tf": 1}, "code_tp.class_and_args_to_dirname": {"tf": 1}, "code_tp.date_dirname": {"tf": 1}, "code_tp.create_agent_and_env": {"tf": 1}, "code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents": {"tf": 1}, "code_tp.agents.base": {"tf": 1}, "code_tp.agents.base.Agent": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.log_data": {"tf": 1}, "code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.run_n_episodes": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.eval_state": {"tf": 1}, "code_tp.agents.base.QLearningAgent.eval_state_batch": {"tf": 1}, "code_tp.agents.base.QLearningAgent.target_value_from_state": {"tf": 1}, "code_tp.agents.base.QLearningAgent.target_value_from_state_batch": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.agents.base.SARSAAgent": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.gridworld": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.show_values": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.agents.replay_buffer": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.ready": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.store": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.sample": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.snake": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.__init__": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.observation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.agents.snake.manual_control": {"tf": 1}, "code_tp.agents.target_value": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state_batch": {"tf": 1}, "code_tp.environments": {"tf": 1}, "code_tp.environments.bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits.__init__": {"tf": 1}, "code_tp.environments.bandits.Bandits.metadata": {"tf": 1}, "code_tp.environments.bandits.Bandits.K": {"tf": 1}, "code_tp.environments.bandits.Bandits.VAR_BETWEEN_SLOTS": {"tf": 1}, "code_tp.environments.bandits.Bandits.SLOT_VAR": {"tf": 1}, "code_tp.environments.bandits.Bandits.AVG_REWARD": {"tf": 1}, "code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.environments.gridworld": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze.x": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze.x": {"tf": 1}, "code_tp.environments.gridworld_utils": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.x": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.maze": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.get_reward_and_done": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.get_image": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.default_reward": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.get_reward_and_done": {"tf": 1}, "code_tp.environments.gridworld_utils.register_env_from_maze": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.environments.snake_utils": {"tf": 1}, "code_tp.mazelab": {"tf": 1}, "code_tp.mazelab.color_style": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.__init__": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.obstacle": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.free": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.agent": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.goal": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.button": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.interruption": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.box": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.lava": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.water": {"tf": 1}, "code_tp.mazelab.env": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.metadata": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reward_range": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.get_image": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}, "code_tp.mazelab.maze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_name": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_value": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_rgb": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_impassable": {"tf": 1}, "code_tp.mazelab.motion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}, "code_tp.mazelab.object": {"tf": 1}, "code_tp.mazelab.object.Object": {"tf": 1}, "code_tp.mazelab.object.Object.__init__": {"tf": 1}, "code_tp.policies": {"tf": 1}, "code_tp.policies.greedy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update_epsilon": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.update_epsilon": {"tf": 1}, "code_tp.policies.softmax_sampling": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy.__init__": {"tf": 1}, "code_tp.utils": {"tf": 1}, "code_tp.utils.isnotebook": {"tf": 1}, "code_tp.utils.logging": {"tf": 1}, "code_tp.utils.logging.add_args_as_info": {"tf": 1}, "code_tp.value_functions": {"tf": 1}, "code_tp.value_functions.base": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.ValueFunction": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.export_f": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.import_f": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.clone": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.enum_actions": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.linear": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.add_bias": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.export_f": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.import_f": {"tf": 1}, "code_tp.value_functions.neural": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.export_f": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.import_f": {"tf": 1}, "code_tp.value_functions.tabular": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.create_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.show_known_states": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.export_f": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.import_f": {"tf": 1}, "code_tp.wrappers": {"tf": 1}, "code_tp.wrappers.utils": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.__init__": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.t": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.observation": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.__init__": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.observation": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.__init__": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.reward": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.__init__": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.observation": {"tf": 1}}, "df": 244}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.mazelab.color_style": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.__init__": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.obstacle": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.free": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.agent": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.goal": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.button": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.interruption": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.box": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.lava": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.water": {"tf": 1}}, "df": 12}}}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.update_epsilon": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 3}}, "q": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.export_f": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.import_f": {"tf": 1}}, "df": 11}}}}}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.class_and_args_to_dirname": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 2}}, "n": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.value_functions.base.ValueFunction.clone": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze.x": {"tf": 1}}, "df": 2}}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.create_agent_and_env": {"tf": 1}}, "df": 1}}}}}}}, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.tabular.TabularQValue.create_state": {"tf": 1}}, "df": 1}}}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}}, "df": 3}}}}}}}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.dict_to_dirname": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.enum_actions": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}}, "df": 8}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.date_dirname": {"tf": 1}}, "df": 1}}}}}}}}}}, "e": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.gridworld_utils.GenericEnv.default_reward": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.mazelab.color_style.DeepMindColor": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.__init__": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.obstacle": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.free": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.agent": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.goal": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.button": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.interruption": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.box": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.lava": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.water": {"tf": 1}}, "df": 11}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents": {"tf": 1}, "code_tp.agents.base": {"tf": 1}, "code_tp.agents.base.Agent": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.log_data": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.select_action": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.step": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.run_episode": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.run_n_episodes": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.train": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.episode_end": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.plot_stats": {"tf": 1.4142135623730951}, "code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.eval_state": {"tf": 1}, "code_tp.agents.base.QLearningAgent.eval_state_batch": {"tf": 1}, "code_tp.agents.base.QLearningAgent.target_value_from_state": {"tf": 1}, "code_tp.agents.base.QLearningAgent.target_value_from_state_batch": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.agents.base.SARSAAgent": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.gridworld": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.show_values": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.agents.replay_buffer": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.ready": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.store": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.sample": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.snake": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.__init__": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.observation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.agents.snake.manual_control": {"tf": 1}, "code_tp.agents.target_value": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state_batch": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.agent": {"tf": 1}}, "df": 58}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.__init__": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.observation": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "o": {"docs": {"code_tp.utils.logging.add_args_as_info": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.value_functions.linear.LinearQValue.add_bias": {"tf": 1}}, "df": 1}}}}}}, "v": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits.AVG_REWARD": {"tf": 1}}, "df": 1}}}}}}}}}}, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.base": {"tf": 1}, "code_tp.agents.base.Agent": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.log_data": {"tf": 1}, "code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.run_n_episodes": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.eval_state": {"tf": 1}, "code_tp.agents.base.QLearningAgent.eval_state_batch": {"tf": 1}, "code_tp.agents.base.QLearningAgent.target_value_from_state": {"tf": 1}, "code_tp.agents.base.QLearningAgent.target_value_from_state_batch": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.agents.base.SARSAAgent": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.value_functions.base": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.ValueFunction": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.export_f": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.import_f": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.clone": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.enum_actions": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}}, "df": 44, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.metadata": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reward_range": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.get_image": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 9}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.mazelab.maze.BaseMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_name": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_value": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_rgb": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_impassable": {"tf": 1}}, "df": 7}}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.__init__": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.metadata": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.K": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.VAR_BETWEEN_SLOTS": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.SLOT_VAR": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.AVG_REWARD": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.reset": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.step": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.close": {"tf": 1.4142135623730951}}, "df": 12}}}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.button": {"tf": 1}}, "df": 1}}}}}, "o": {"docs": {}, "df": 0, "x": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.box": {"tf": 1}}, "df": 1}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.__init__": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.reward": {"tf": 1}}, "df": 3}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state": {"tf": 1}}, "df": 2, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state_batch": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "_": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "_": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.environments.bandits.Bandits.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.__init__": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.__init__": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}, "code_tp.mazelab.object.Object.__init__": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.__init__": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.__init__": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.__init__": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.__init__": {"tf": 1}}, "df": 30}}}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.utils.logging": {"tf": 1}, "code_tp.utils.logging.add_args_as_info": {"tf": 1}}, "df": 2, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.agents.base.Agent.log_data": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {"code_tp.wrappers.utils.LogScaleObs": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.__init__": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.t": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.observation": {"tf": 1}}, "df": 4}}}}}}}}}, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.lava": {"tf": 1}}, "df": 1, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze.x": {"tf": 1}}, "df": 2}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.linear": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.add_bias": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.export_f": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.import_f": {"tf": 1}}, "df": 8, "q": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.add_bias": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.export_f": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.import_f": {"tf": 1}}, "df": 7}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}}, "df": 3}}}}}}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 5}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.replay_buffer.ReplayBuffer.store": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.base.SARSAAgent": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}}, "df": 2}}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.replay_buffer.ReplayBuffer.sample": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent.show_values": {"tf": 1}}, "df": 1}}}}, "k": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.tabular.TabularQValue.show_known_states": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.snake": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.__init__": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState.observation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.agents.snake.manual_control": {"tf": 1}}, "df": 11, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}}, "df": 4}}}}}}}}}}}}}, "_": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.snake_utils": {"tf": 1}}, "df": 1}}}}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits.SLOT_VAR": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}}, "df": 2}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}}, "df": 2, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}}, "df": 1}}}}}}}, "f": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.policies.softmax_sampling": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy.__init__": {"tf": 1}}, "df": 3}}}}}}, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}}}}}}, "t": {"docs": {"code_tp.wrappers.utils.LogScaleObs.t": {"tf": 1}}, "df": 1, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 2, "_": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6}}}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.target_value": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state_batch": {"tf": 1}}, "df": 6, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.QLearningAgent.target_value_from_state": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.agents.base.QLearningAgent.target_value_from_state_batch": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state_batch": {"tf": 1}}, "df": 5}}}}}}}}}}}, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.tabular": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.create_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.show_known_states": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.export_f": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.import_f": {"tf": 1}}, "df": 9, "q": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.value_functions.tabular.TabularQValue": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.create_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.show_known_states": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.export_f": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.import_f": {"tf": 1}}, "df": 8}}}}}, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.wrappers.utils.TabularObservation": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.__init__": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.observation": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.mazelab.maze.BaseMaze.to_name": {"tf": 1}}, "df": 1}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.mazelab.maze.BaseMaze.to_value": {"tf": 1}}, "df": 1}}}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "b": {"docs": {"code_tp.mazelab.maze.BaseMaze.to_rgb": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.mazelab.maze.BaseMaze.to_impassable": {"tf": 1}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 2}}}, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.wrappers.utils.TimeToChannels": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.__init__": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.observation": {"tf": 1}}, "df": 3}}}}}}}}}}}}}, "r": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}}, "df": 1}}}}}}, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.run_n_episodes": {"tf": 1}}, "df": 1}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}}, "df": 3}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}}, "df": 4}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.agents.replay_buffer": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.ready": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.store": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.sample": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}}, "df": 9}}}}}, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.agents.replay_buffer.ReplayBuffer": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.ready": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.store": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBuffer.sample": {"tf": 1}}, "df": 5, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.agents.replay_buffer.ReplayBuffer.ready": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 3}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.environments.gridworld_utils.register_env_from_maze": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.wrappers.utils.BoredomWrapper.reward": {"tf": 1}}, "df": 1, "_": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.mazelab.env.BaseEnv.reward_range": {"tf": 1}}, "df": 1}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.episode_end": {"tf": 1}}, "df": 1}}}}}}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.QLearningAgent.eval_state": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state": {"tf": 1}}, "df": 2, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.agents.base.QLearningAgent.eval_state_batch": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.eval_state_batch": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.maze": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.get_reward_and_done": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.get_image": {"tf": 1}, "code_tp.mazelab.env": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.metadata": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reward_range": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.get_image": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 17, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments": {"tf": 1}, "code_tp.environments.bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits.__init__": {"tf": 1}, "code_tp.environments.bandits.Bandits.metadata": {"tf": 1}, "code_tp.environments.bandits.Bandits.K": {"tf": 1}, "code_tp.environments.bandits.Bandits.VAR_BETWEEN_SLOTS": {"tf": 1}, "code_tp.environments.bandits.Bandits.SLOT_VAR": {"tf": 1}, "code_tp.environments.bandits.Bandits.AVG_REWARD": {"tf": 1}, "code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.environments.gridworld": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze.x": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze.x": {"tf": 1}, "code_tp.environments.gridworld_utils": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.x": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.maze": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.get_reward_and_done": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.get_image": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.default_reward": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.get_reward_and_done": {"tf": 1}, "code_tp.environments.gridworld_utils.register_env_from_maze": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.environments.snake_utils": {"tf": 1}}, "df": 41}}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.enum_discrete": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.enum_actions": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}}, "df": 2}}}, "g": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update_epsilon": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}}, "df": 5}}}}}}}}}}}}, "x": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.value_functions.base.ValueFunction.export_f": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.export_f": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.export_f": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.export_f": {"tf": 1}}, "df": 4}}}}}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 2}}}}}}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies": {"tf": 1}, "code_tp.policies.greedy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update_epsilon": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.update_epsilon": {"tf": 1}, "code_tp.policies.softmax_sampling": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy.__init__": {"tf": 1}}, "df": 19}}}}}}, "q": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.base.QLearningAgent": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.eval_state": {"tf": 1}, "code_tp.agents.base.QLearningAgent.eval_state_batch": {"tf": 1}, "code_tp.agents.base.QLearningAgent.target_value_from_state": {"tf": 1}, "code_tp.agents.base.QLearningAgent.target_value_from_state_batch": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 9}}}}}}}}}}}, "g": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.gridworld": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.show_values": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.environments.gridworld": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze.x": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze.x": {"tf": 1}}, "df": 9, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.show_values": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}, "_": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.gridworld_utils": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.x": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.maze": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.get_reward_and_done": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.get_image": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.default_reward": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.get_reward_and_done": {"tf": 1}, "code_tp.environments.gridworld_utils.register_env_from_maze": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}}, "df": 22}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update_epsilon": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.__init__": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.update_epsilon": {"tf": 1}}, "df": 15}, "y": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.__init__": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.default_reward": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.get_reward_and_done": {"tf": 1}}, "df": 3}}}}}}}}, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.gridworld_utils.Env.get_reward_and_done": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv.get_reward_and_done": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.environments.gridworld_utils.Env.get_image": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.get_image": {"tf": 1}}, "df": 2}}}}}}}, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.goal": {"tf": 1}}, "df": 1}}}}, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.AddDirectionToSnakeState.observation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.observation": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.observation": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.observation": {"tf": 1}}, "df": 5}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.obstacle": {"tf": 1}}, "df": 1}}}}}, "j": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.object": {"tf": 1}, "code_tp.mazelab.object.Object": {"tf": 1.4142135623730951}, "code_tp.mazelab.object.Object.__init__": {"tf": 1.4142135623730951}}, "df": 3}}}}}, "c": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}}, "df": 1}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "j": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}}, "df": 3}}}}}}}}}, "n": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.manual_control": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "z": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.x": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.maze": {"tf": 1}, "code_tp.mazelab.maze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_name": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_value": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_rgb": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_impassable": {"tf": 1}}, "df": 13, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {"code_tp.mazelab": {"tf": 1}, "code_tp.mazelab.color_style": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.__init__": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.obstacle": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.free": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.agent": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.goal": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.button": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.interruption": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.box": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.lava": {"tf": 1}, "code_tp.mazelab.color_style.DeepMindColor.water": {"tf": 1}, "code_tp.mazelab.env": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.metadata": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reward_range": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.get_image": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}, "code_tp.mazelab.maze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_name": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_value": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_rgb": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.to_impassable": {"tf": 1}, "code_tp.mazelab.motion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}, "code_tp.mazelab.object": {"tf": 1}, "code_tp.mazelab.object.Object": {"tf": 1}, "code_tp.mazelab.object.Object.__init__": {"tf": 1}}, "df": 51}}}}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.environments.bandits.Bandits.metadata": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.metadata": {"tf": 1}}, "df": 2}}}}}}}, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.mazelab.motion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}}, "df": 17}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}}, "df": 10}}}}}}}}, "k": {"docs": {"code_tp.environments.bandits.Bandits.K": {"tf": 1}}, "df": 1}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.VAR_BETWEEN_SLOTS": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions": {"tf": 1}, "code_tp.value_functions.base": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.ValueFunction": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.export_f": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.import_f": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.clone": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.enum_actions": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.linear": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.add_bias": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.export_f": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.import_f": {"tf": 1}, "code_tp.value_functions.neural": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.export_f": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.import_f": {"tf": 1}, "code_tp.value_functions.tabular": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.create_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.show_known_states": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.export_f": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.import_f": {"tf": 1}}, "df": 51}}}}}}, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.ValueFunction": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.export_f": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.import_f": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.clone": {"tf": 1}}, "df": 8}}}}}}}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}}, "df": 6}}}}}}}}}}}}}, "x": {"docs": {"code_tp.environments.gridworld.LavaMaze.x": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze.x": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.x": {"tf": 1}}, "df": 3}, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.free": {"tf": 1}}, "df": 1}}, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}}, "df": 4, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state_batch": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.interruption": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {"code_tp.utils.isnotebook": {"tf": 1}}, "df": 1}}}}}}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.value_functions.base.ValueFunction.import_f": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.import_f": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.import_f": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.import_f": {"tf": 1}}, "df": 4}}}}}}}}, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.mazelab.color_style.DeepMindColor.water": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}}, "df": 2}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.wrappers": {"tf": 1}, "code_tp.wrappers.utils": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.__init__": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.t": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.observation": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.__init__": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.observation": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.__init__": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.reward": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.__init__": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.observation": {"tf": 1}}, "df": 15}}}}}}}, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}}, "df": 2, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.value_functions.neural": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.best_action_value_from_state_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.export_f": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.import_f": {"tf": 1}}, "df": 15}}}}}}, "u": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 6, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.policies.greedy.EGreedyPolicy.update_epsilon": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy.update_epsilon": {"tf": 1}}, "df": 2}}}}}}}, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 2}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.utils": {"tf": 1}, "code_tp.utils.isnotebook": {"tf": 1}, "code_tp.utils.logging": {"tf": 1}, "code_tp.utils.logging.add_args_as_info": {"tf": 1}, "code_tp.wrappers.utils": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.__init__": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.t": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs.observation": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.__init__": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation.observation": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.__init__": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper.reward": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.__init__": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels.observation": {"tf": 1}}, "df": 18}}}}}}, "doc": {"root": {"0": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}}, "df": 4}, "1": {"6": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 2}, "docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 9}, "2": {"0": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.4142135623730951}}, "df": 1}, "docs": {"code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}}, "df": 2}, "3": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}}, "df": 4}, "4": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}}, "df": 3}, "5": {"docs": {"code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.4142135623730951}}, "df": 2}, "6": {"docs": {"code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}}, "df": 1}, "7": {"docs": {"code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}}, "df": 1}, "8": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.create_agent_and_env": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}}, "df": 2}}}, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 2}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}}, "df": 11}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 4}}}}}, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 7}}}}}, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {"code_tp.wrappers.utils.LogScaleObs": {"tf": 1}}, "df": 1}}, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}}, "df": 10}}}, "g": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 2}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.mazelab.object.Object": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.manual_control": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}}, "df": 5, "t": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}}, "df": 1}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 3}}}}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1.7320508075688772}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1.7320508075688772}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1.4142135623730951}}, "df": 11}}}}, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 2}}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.Agent": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels": {"tf": 1}}, "df": 33}}, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 5}}}}, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.object.Object": {"tf": 1}}, "df": 1}}}, "p": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}, "r": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 4}}}, "a": {"docs": {"code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}}, "df": 9, "r": {"docs": {"code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 17, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "\u00e8": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 15}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}}, "df": 9, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}, "r": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 8}}}, "e": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}}}, "m": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}}, "df": 2}}, "s": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 2}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 2}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 2}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 6}}}, "x": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "u": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}}, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}}, "df": 1}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}}}}}}}}}, "\u00e9": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}}}}}, "(": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}}, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 4}}}, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.create_agent_and_env": {"tf": 1}}, "df": 1, "e": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 2}}, "m": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6, "b": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 3}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 1}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 12}, "h": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}}, "df": 2}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}}, "df": 2}}}}}}}}, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 2}}}}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1}}}}}}, "'": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}}, "df": 1}}}}}}}}}}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 5}}, "w": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}}, "df": 5, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 2}}}}}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 6}}}}, "t": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "k": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}}, "df": 16}}}, "p": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}}, "p": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}, "n": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 2.23606797749979}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}}, "df": 2}}, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 5, "i": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 11, "s": {"docs": {"code_tp.agents.target_value.TargetValueAgent": {"tf": 1}}, "df": 1, "\u00e9": {"docs": {"code_tp.create_agent_and_env": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 3}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}}, "df": 3}}}}}}}}, "n": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents.base.Agent.select_action": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1.4142135623730951}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1.4142135623730951}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1.4142135623730951}, "code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}}, "df": 38, "i": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 11}}, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 1}}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}}}, "s": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}}, "df": 9, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "p": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 3}}}}}, "f": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.7320508075688772}}, "df": 1, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.create_agent_from_env": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.train": {"tf": 1.4142135623730951}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.4142135623730951}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.ValueFunction": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 28}}}}}}, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}}, "df": 3}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1}}}, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1, "(": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}}}}}}}, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.mazelab.object.Object": {"tf": 1}}, "df": 1, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}}, "df": 2}}}}}}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 7}, "b": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}}, "df": 1}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}}, "df": 5}, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}}, "df": 12}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1.4142135623730951}}, "df": 2}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 7}}}}}}, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.mazelab.object.Object": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.create_agent_from_env": {"tf": 1.7320508075688772}, "code_tp.agents.base.Agent": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1.7320508075688772}, "code_tp.agents.base.Agent.step": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.train": {"tf": 2.6457513110645907}, "code_tp.agents.base.Agent.episode_end": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1.7320508075688772}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1.7320508075688772}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1.7320508075688772}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1.7320508075688772}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 2.6457513110645907}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1.7320508075688772}, "code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1.4142135623730951}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 2}, "code_tp.agents.snake.manual_control": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1.7320508075688772}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1.7320508075688772}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 2}, "code_tp.value_functions.base.ValueFunction": {"tf": 2}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 2.23606797749979}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 2.23606797749979}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1.7320508075688772}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 2.23606797749979}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1.7320508075688772}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 2.23606797749979}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 2.23606797749979}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1.7320508075688772}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 2.23606797749979}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 2.23606797749979}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.tabular.TabularQValue": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 2.23606797749979}, "code_tp.wrappers.utils.LogScaleObs": {"tf": 1.4142135623730951}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1.4142135623730951}, "code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels": {"tf": 1}}, "df": 57, "f": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.4142135623730951}}, "df": 3, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}}, "df": 1}}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}, "code_tp.mazelab.object.Object": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1.4142135623730951}}, "df": 5}}}, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.mazelab.color_style.DeepMindColor": {"tf": 1}}, "df": 1}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1.7320508075688772}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1.7320508075688772}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels": {"tf": 1}}, "df": 20}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1.4142135623730951}}, "df": 5}}}}}, "n": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6}, "e": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1.4142135623730951}}, "df": 4}, "'": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 3}}}, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}}, "df": 6}}}}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 4}}}}, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 2}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1}}, "df": 6, "i": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1, "\u00e9": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1}}}}}, "\u00e9": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "\u00e9": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.target_value.TargetValueAgent": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.wrappers.utils.LogScaleObs": {"tf": 1}}, "df": 1}}}}, "\u00e9": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 7, "\u00e9": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}}, "df": 1}}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 4}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 2, "r": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}}}}}, "c": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 9}}}}}, "t": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 4}}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.wrappers.utils.TabularObservation": {"tf": 1}}, "df": 1}}}}}}}}, "u": {"docs": {"code_tp.agents.base.QLearningAgent": {"tf": 1}, "code_tp.agents.base.SARSAAgent": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 14, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 5}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 4}}}}}, "'": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1.4142135623730951}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.4142135623730951}}, "df": 3}}}}}}, "p": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}, "\u00e9": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 2}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 2}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}}, "df": 3}}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}}, "df": 3}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}}, "df": 2, "e": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1.4142135623730951}}, "df": 6}}}, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 2}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 2}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 2}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 2}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 2}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1.4142135623730951}}, "df": 8}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}}, "df": 3}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}, "y": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 8}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.create_agent_from_env": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1.7320508075688772}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.7320508075688772}, "code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1.7320508075688772}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1.4142135623730951}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1.4142135623730951}}, "df": 25, "n": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}}, "df": 1}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}}, "'": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 20}}}}, "l": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.agents.base.QLearningAgent": {"tf": 1}, "code_tp.agents.base.SARSAAgent": {"tf": 1}}, "df": 2}}}}}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "\u00e9": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1.4142135623730951}}, "df": 3}}}}}}}}, "n": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1.4142135623730951}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 3}}}}}}, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}}, "df": 1}}}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}}}}, "\u00e9": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}}, "df": 2}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 5}}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1.4142135623730951}}, "df": 3}}}}}}}, "e": {"docs": {"code_tp.create_agent_from_env": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent": {"tf": 1}, "code_tp.agents.base.Agent.__init__": {"tf": 1.7320508075688772}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.run_episode": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.train": {"tf": 1.7320508075688772}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.base.Agent.plot_stats": {"tf": 1.7320508075688772}, "code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1.7320508075688772}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.7320508075688772}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1.7320508075688772}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1.7320508075688772}, "code_tp.agents.snake.manual_control": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1.4142135623730951}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1.4142135623730951}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1.4142135623730951}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs": {"tf": 1.4142135623730951}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1.4142135623730951}, "code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels": {"tf": 1.7320508075688772}}, "df": 48, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 8}}}}, "s": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 2}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.QLearningAgent": {"tf": 1}, "code_tp.agents.base.SARSAAgent": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 6}}}}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}}, "df": 1}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1.4142135623730951}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}}, "df": 8}}}, "o": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 2}}}}}, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 2}}}}}}}}, "r": {"docs": {"code_tp.agents.target_value.TargetValueAgent": {"tf": 1}}, "df": 1}}, "t": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1.4142135623730951}}, "df": 1}, "r": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 4, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1.4142135623730951}}, "df": 4}}}}}, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 4}}}}}}, "e": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2, "x": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "\u00e9": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}}, "df": 1}}}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "\u00e9": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}}}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}}, "df": 1}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}, "t": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 2}}, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 3}}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}, "n": {"docs": {"code_tp.create_agent_from_env": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1.7320508075688772}}, "df": 13, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}}, "df": 1}}}}}}}, "v": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 9, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.reset": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1.7320508075688772}, "code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 17, "n": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 17}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "'": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1.4142135623730951}}, "df": 7}}}}}}}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 1}}}}}, "'": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1.4142135623730951}}, "df": 1}}, "t": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 2, "\u00e9": {"docs": {"code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}}, "df": 4}, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 2}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}}, "df": 1}}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}}, "d": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1.4142135623730951}}, "df": 4}}, "t": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}}, "df": 20, "c": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.object.Object": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 6}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 18}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 8}}}}, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.RandomAgent": {"tf": 1}}, "df": 2, "\u00e9": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 3}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}}, "df": 4}}}, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1.4142135623730951}}, "df": 7}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1.7320508075688772}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1.4142135623730951}}, "df": 2, "_": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "x": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}}}}}, "{": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "x": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1, "}": {"docs": {}, "df": 0, ")": {"docs": {}, "df": 0, "/": {"2": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}}}}}}}}, "=": {"0": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}, "1": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}}}}}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}}, "g": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1.4142135623730951}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 5, "i": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1.4142135623730951}}, "df": 12, "r": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}, ",": {"docs": {}, "df": 0, "+": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}}, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6, "d": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 2}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1, "\u00e9": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1.4142135623730951}}, "df": 3}}}}}}, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1.7320508075688772}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1.7320508075688772}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}}, "df": 4}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}}, "df": 5}}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}}, "df": 1}, "v": {"docs": {"code_tp.wrappers.utils.TabularObservation": {"tf": 1}}, "df": 1}}}, "\u00e9": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.wrappers.utils.TimeToChannels": {"tf": 1}}, "df": 1}}}}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "\u00e9": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.QLearningAgent": {"tf": 1}, "code_tp.agents.base.SARSAAgent": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}}, "df": 3}}}}}, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}}, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.mazelab.object.Object": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.4142135623730951}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}, "t": {"docs": {}, "df": 0, "'": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}, "\u00e9": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.base.enum_discrete": {"tf": 1}}, "df": 1}}}}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}, "g": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}}, "df": 2, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1.4142135623730951}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1.4142135623730951}, "code_tp.wrappers.utils.LogScaleObs": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1}}, "df": 31}}}, "u": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 3, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 2}}}}}}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}}, "df": 4}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 2}}, "r": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}}}, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}}, "df": 2}}}}, "i": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1.4142135623730951}}, "df": 3}}, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "(": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "\u00e9": {"docs": {}, "df": 0, "o": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 2}}, "e": {"docs": {}, "df": 0, "o": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 2}}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 1}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}}, "df": 2}}}}}}, "(": {"docs": {"code_tp.value_functions.base.ValueFunction": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "o": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}}, "df": 1}}, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1.7320508075688772}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.7320508075688772}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.7320508075688772}}, "df": 4}}}}}, "l": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 4}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 2}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 4}}}, "l": {"docs": {}, "df": 0, "\u00e8": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}}}}}}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "b": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1.4142135623730951}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1.4142135623730951}}, "df": 2}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.wrappers.utils.TimeToChannels": {"tf": 1}}, "df": 1}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 2}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.manual_control": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 7}}}}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}}, "df": 1}}}}}, "v": {"1": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1, "(": {"docs": {}, "df": 0, "x": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}, "2": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1, "d": {"docs": {}, "df": 0, "(": {"1": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}, "2": {"0": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "docs": {}, "df": 0}}, "(": {"docs": {}, "df": 0, "x": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}, "docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}, "r": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1, "_": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}}, "df": 1, "/": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 3}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 2}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1.7320508075688772}}, "df": 1}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.agents.base.Agent": {"tf": 1}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.7320508075688772}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 27, "'": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits.close": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1.4142135623730951}}, "df": 6}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 2}}}}}}, "r": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}}, "df": 7}}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}}, "df": 4, "t": {"docs": {"code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 7}}, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 4}}}}, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.4142135623730951}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 10}}, "n": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1}}, "r": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 2}}}, "o": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "x": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.step": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1.4142135623730951}}, "df": 12, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 3}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.wrappers.utils.TimeToChannels": {"tf": 1}}, "df": 1}, "u": {"docs": {}, "df": 0, "x": {"docs": {"code_tp.wrappers.utils.TimeToChannels": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 4, "b": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 5}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 6}}}}}}}, "t": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1.4142135623730951}}, "df": 1, "o": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.base.Agent": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}}, "df": 6, "t": {"docs": {"code_tp.create_agent_from_env": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}}, "df": 3}, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.4142135623730951}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1.4142135623730951}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1.4142135623730951}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1.4142135623730951}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 19}, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1, "x": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 2}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.tabular.TabularQValue": {"tf": 1}}, "df": 1}}}}}}, "u": {"docs": {}, "df": 0, "x": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 2}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 2}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 2}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 2}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 10}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 3}}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}}}}}}, "k": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1.4142135623730951}}, "df": 13}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.wrappers.utils.LogScaleObs": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1}}, "df": 4}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.wrappers.utils.TabularObservation": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.7320508075688772}}, "df": 1, "_": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 2}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 2}}}, "e": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 3, "e": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 1}}}, "u": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1.4142135623730951}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.4142135623730951}}, "df": 3, "_": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1.4142135623730951}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.4142135623730951}}, "df": 2}}}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}}, "df": 2}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}}, "df": 9, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.wrappers.utils.TimeToChannels": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 2}}}}, "x": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 2}}}, "u": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 8}}, "r": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}}}, "r": {"docs": {}, "df": 0, "\u00e9": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}}, "df": 3}}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 2}}}}}}}, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.value_functions.base.ValueFunction": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1}}, "df": 5}}}}, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.base.Agent": {"tf": 1}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 15}}, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1.4142135623730951}}, "df": 5}}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 7}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 5, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}}, "df": 1}}, "x": {"docs": {"code_tp.wrappers.utils.TabularObservation": {"tf": 1}}, "df": 1}}, "r": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1}}}}}}, "t": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 4}}}}}}, "u": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 2}}}}}}, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent": {"tf": 1}, "code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 12, "'": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}}, "u": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}}, "df": 3, "c": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}}, "df": 1}}}, "x": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}}}}, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 2}}}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}, "code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 2}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 2}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 2}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 2}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.tabular.TabularQValue.__init__": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1.4142135623730951}}, "df": 30, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}}}}, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.base.Agent.episode_end": {"tf": 1}}, "df": 1}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}, "p": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}}}}}, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1.4142135623730951}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 5, "\u00e9": {"docs": {"code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}}, "df": 3}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 2}}}}}, "i": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}, "r": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 6, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train": {"tf": 1}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 5}}}}}}, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "'": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}}}, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}}, "df": 3}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.wrappers.utils.LogScaleObs": {"tf": 1}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "\u00e9": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.RandomAgent": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}}, "df": 3}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 2}}}, "i": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion.north": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.south": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.west": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.north": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.south": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.west": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.east": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.northeast": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southwest": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.southeast": {"tf": 1}}, "df": 12}}, "g": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}}}}, "j": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.wrappers.utils.BoredomWrapper": {"tf": 1}}, "df": 3}}}}, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1.4142135623730951}}, "df": 1}}, "s": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 2}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 3}}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 5}}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}}, "b": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}}, "df": 5}}, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "g": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2, "y": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1.4142135623730951}}, "df": 18}}, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.agents.base.QLearningAgent.__init__": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.__init__": {"tf": 1}}, "df": 2}}}, "r": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 2}}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.wrappers.utils.TabularObservation": {"tf": 1}}, "df": 1, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}}}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 3}}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1.4142135623730951}}, "df": 2}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1.7320508075688772}}, "df": 1, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "(": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 4}}}}}}}}}, "t": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1.4142135623730951}}, "df": 1}}, "s": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}}, "df": 4}}}}}}, "u": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.train": {"tf": 1.4142135623730951}, "code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.agents.gridworld.GridworldTabularValueAgent.train": {"tf": 1.4142135623730951}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}}, "df": 6, "\u00e9": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}}, "df": 2}}}}}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 3}}}}, "e": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}}, "df": 1, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}}, "df": 2}}}, "a": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 7}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.snake.manual_control": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {"code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}}, "df": 2}}, "l": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.7320508075688772}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 7}, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 2.6457513110645907}}, "df": 5, "=": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}}}}, "t": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1.7320508075688772}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.7320508075688772}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 7}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}}, "u": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 5}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}}, "df": 2}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 3, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "\u00e9": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}}, "df": 1}}}}, "(": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}}}}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.7320508075688772}}, "df": 2}}}}}, "r": {"docs": {"code_tp.policies.greedy.GreedyQPolicy": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 8, "e": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "\u00e9": {"docs": {"code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 5}}}}}}}, "b": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 5}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 6, "t": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6}}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}}, "df": 4, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}}, "df": 2}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}}, "df": 2}}}}}}}, "f": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "(": {"5": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}}}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}}, "df": 5, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "\u00e9": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6}}}}}}}}, "t": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 2, "e": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1.4142135623730951}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1.4142135623730951}}, "df": 12}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 9}}, "r": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 2, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2, "i": {"docs": {}, "df": 0, "o": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 2}}}}}, "u": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}}}, "y": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "i": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}}, "df": 5, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.plot_stats": {"tf": 1}, "code_tp.agents.base.QLearningAgent.plot_stats": {"tf": 1}}, "df": 2}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 5}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.base.Agent.episode_end": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}, "p": {"docs": {}, "df": 0, "\u00e9": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.object.Object": {"tf": 1}, "code_tp.value_functions.base.enum_discrete": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1.4142135623730951}}, "df": 7}}}}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 4, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1.4142135623730951}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}}, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1}}, "df": 1}}}}, "'": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}}}}, "r": {"docs": {}, "df": 0, "\u00e9": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}}, "df": 2}}}}}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6}}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.wrappers.utils.TimeToChannels": {"tf": 1}}, "df": 1}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.agents.base.Agent.select_action": {"tf": 1}, "code_tp.agents.base.RandomAgent.select_action": {"tf": 1}, "code_tp.agents.base.QLearningAgent.select_action": {"tf": 1}}, "df": 3, "t": {"docs": {"code_tp.value_functions.base.DiscreteQFunction.from_state": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.from_state": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.from_state": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.from_state": {"tf": 1}}, "df": 4}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 2.6457513110645907}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 2.6457513110645907}}, "df": 6, "(": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "=": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}}}}}}}}}, "\u00e7": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.episode_end": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.observation": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 4}}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.step": {"tf": 2}, "code_tp.environments.bandits.Bandits.render": {"tf": 2.23606797749979}, "code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 2}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 2}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 2}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 2.23606797749979}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 16}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.reset": {"tf": 2}, "code_tp.environments.bandits.Bandits.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 2}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 2}}, "df": 11}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}}, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.step": {"tf": 1.7320508075688772}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1.7320508075688772}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1.7320508075688772}}, "df": 8, "_": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}}}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 3, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 2}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}}, "i": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}, "g": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 2}}}}, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "(": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}}, "df": 6}}}}}}, "n": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}}, "df": 4}, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1.4142135623730951}}, "df": 4, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}}, "df": 2}}}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}, "c": {"docs": {}, "df": 0, "{": {"2": {"docs": {}, "df": 0, "\\": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "}": {"docs": {}, "df": 0, "{": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "{": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}, "docs": {}, "df": 0}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 5, "_": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.agents.base.Agent.episode_end": {"tf": 1}}, "df": 1}}}}}}}}}, "g": {"docs": {}, "df": 0, "b": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 2, "_": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.7320508075688772}}, "df": 2}}}}}}}}}, "q": {"docs": {"code_tp.agents.base.QLearningAgent": {"tf": 1}, "code_tp.agents.base.SARSAAgent": {"tf": 1}}, "df": 2, "u": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.call_batch": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.base.DiscreteQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.call_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1.4142135623730951}}, "df": 11, "p": {"docs": {"code_tp.agents.snake.make_feature_snake_env": {"tf": 1}}, "df": 1, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.policies.greedy.RandomPolicy": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy": {"tf": 1}}, "df": 2}}}}, "e": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"code_tp.agents.gridworld.GridworldTabularValueAgent": {"tf": 1}}, "df": 1}}}}}}}}}}, "(": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, ",": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction": {"tf": 1}}, "df": 4}}}}}, "j": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}}, "df": 2}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 15}, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}}, "df": 1}}}}}, "y": {"docs": {"code_tp.agents.base.Agent.__init__": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.__init__": {"tf": 1}, "code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 4, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 3}}}}}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.base.Agent.train_with_transition": {"tf": 1}, "code_tp.agents.base.RandomAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.QLearningAgent.train_with_transition": {"tf": 1}, "code_tp.agents.base.SARSAAgent.train_with_transition": {"tf": 1}, "code_tp.agents.replay_buffer.ReplayBufferAgent.train_with_transition": {"tf": 1}, "code_tp.agents.target_value.TargetValueAgent.train_with_transition": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 10, "t": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}}, "df": 3}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1}}, "df": 2}}}}, "h": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1, "o": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 7}}, ":": {"docs": {}, "df": 0, "`": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "_": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}}, "df": 2}}}}}}}, "\u00e9": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.agents.base.Agent.step": {"tf": 1}, "code_tp.agents.base.Agent.episode_end": {"tf": 1}, "code_tp.policies.greedy.RandomPolicy.update": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.update": {"tf": 1}, "code_tp.value_functions.base.ValueFunction.update_batch": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalQFunction.update_batch": {"tf": 1.4142135623730951}}, "df": 6}}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.agents.snake.manual_control": {"tf": 1}}, "df": 1}}}}, "i": {"docs": {"code_tp.policies.softmax_sampling.SoftmaxSamplingPolicy": {"tf": 1}}, "df": 1, "n": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1.4142135623730951}}, "df": 5, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.value_functions.base.ValueFunction.update": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.update": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.update": {"tf": 1}, "code_tp.value_functions.tabular.TabularQValue.update": {"tf": 1}}, "df": 4}}}}}}}, "x": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.policies.greedy.CosineEGreedyPolicy": {"tf": 1.4142135623730951}}, "df": 5}, "k": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 4}}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 4, "i": {"docs": {"code_tp.value_functions.base.ValueFunction.__init__": {"tf": 1}, "code_tp.value_functions.base.DiscreteQFunction.__init__": {"tf": 1}, "code_tp.value_functions.linear.LinearQValue.__init__": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalQFunction.__init__": {"tf": 1}}, "df": 4}}}}}}}, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 3}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 3}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 3, "=": {"docs": {}, "df": 0, "'": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}}}, "l": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1, "(": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 2.23606797749979}, "code_tp.value_functions.neural.ConvolutionalNN.__init__": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 3, "a": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "(": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "(": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}}}}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 5, "t": {"docs": {"code_tp.agents.base.Agent.run_episode": {"tf": 1}}, "df": 1}}, "u": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.__init__": {"tf": 1.4142135623730951}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}}, "df": 3}, "b": {"docs": {}, "df": 0, "j": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}, "code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.bandits.Bandits.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Maze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze.make_objects": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.make_objects": {"tf": 1}, "code_tp.mazelab.object.Object": {"tf": 1.4142135623730951}}, "df": 16}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.agents.snake.SnakeFeatureObservation.OC": {"tf": 1}, "code_tp.environments.bandits.Bandits": {"tf": 1.4142135623730951}, "code_tp.environments.bandits.Bandits.reset": {"tf": 1.7320508075688772}, "code_tp.environments.bandits.Bandits.step": {"tf": 1.7320508075688772}, "code_tp.environments.gridworld_utils.Env": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1.7320508075688772}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1.7320508075688772}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1.4142135623730951}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1.7320508075688772}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1.7320508075688772}, "code_tp.wrappers.utils.LogScaleObs": {"tf": 1}, "code_tp.wrappers.utils.TabularObservation": {"tf": 1}, "code_tp.wrappers.utils.TimeToChannels": {"tf": 1}}, "df": 15, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {"code_tp.mazelab.object.Object": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.value_functions.base.enum_discrete": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits.close": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.close": {"tf": 1}}, "df": 3, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}}}}}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1.4142135623730951}}, "df": 1}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}}}, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.agents.snake.AddDirectionToSnakeState": {"tf": 1}, "code_tp.agents.snake.SnakeFeatureObservation": {"tf": 1}, "code_tp.agents.snake.make_feature_snake_env": {"tf": 1.7320508075688772}, "code_tp.agents.snake.make_tabular_snake_env": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 5}}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 5}}, "y": {"docs": {"code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 6}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"code_tp.environments.bandits.Bandits.reset": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.reset": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.reset": {"tf": 1}}, "df": 3}}, "n": {"docs": {}, "df": 0, "'": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.env.BaseEnv.seed": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 5}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}}, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}}, "df": 2}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.mazelab.motion.VonNeumannMotion": {"tf": 1}, "code_tp.mazelab.motion.VonNeumannMotion.__init__": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion": {"tf": 1}, "code_tp.mazelab.motion.MooreMotion.__init__": {"tf": 1}}, "df": 4}}}}, "k": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {"code_tp.environments.bandits.Bandits": {"tf": 1}, "code_tp.environments.gridworld_utils.Env": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericEnv": {"tf": 1}, "code_tp.mazelab.env.BaseEnv": {"tf": 1}}, "df": 4}}}, "e": {"docs": {}, "df": 0, "y": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1}}, "df": 2}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {"code_tp.environments.bandits.Bandits.step": {"tf": 1}, "code_tp.environments.gridworld_utils.Env.step": {"tf": 1}, "code_tp.environments.gridworld_utils.StochasticWrapper.step": {"tf": 1}, "code_tp.mazelab.env.BaseEnv.step": {"tf": 1}}, "df": 4, "e": {"docs": {}, "df": 0, "r": {"docs": {"code_tp.environments.gridworld.LavaMaze": {"tf": 1}, "code_tp.environments.gridworld.CliffMaze": {"tf": 1}, "code_tp.environments.gridworld_utils.Maze": {"tf": 1}, "code_tp.environments.gridworld_utils.GenericMaze": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze": {"tf": 1}}, "df": 5}}}}, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {"code_tp.environments.gridworld_utils.Maze.size": {"tf": 1}, "code_tp.mazelab.maze.BaseMaze.size": {"tf": 1}}, "df": 2}}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 2}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 2}}, "df": 2}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN.forward": {"tf": 1}}, "df": 1}}}}, "x": {"docs": {"code_tp.environments.bandits.Bandits.render": {"tf": 1.4142135623730951}, "code_tp.mazelab.env.BaseEnv.render": {"tf": 1.4142135623730951}, "code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1.4142135623730951}}, "df": 3}, "_": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "_": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1, "(": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "v": {"docs": {"code_tp.environments.gridworld_utils.StochasticWrapper": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "f": {"docs": {"code_tp.value_functions.neural.ConvolutionalNN": {"tf": 1}}, "df": 1}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "_": {"docs": {}, "df": 0, "_": {"docs": {"code_tp.policies.greedy.RandomPolicy.test": {"tf": 1}, "code_tp.policies.greedy.EGreedyPolicy.test": {"tf": 1}}, "df": 2}}}}}}}}, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {"code_tp.wrappers.utils.LogScaleObs": {"tf": 1}}, "df": 1}}}}}}}, "pipeline": ["trimmer", "stopWordFilter", "stemmer"], "_isPrebuiltIndex": true};

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.addField("qualname");
            this.addField("fullname");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();